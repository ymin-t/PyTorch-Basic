{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15b02d8d",
   "metadata": {},
   "source": [
    "# MLP Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a01abcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bf751d",
   "metadata": {},
   "source": [
    "## 1. Dataset Creation\n",
    "\n",
    "In this dataset, we create spiral design plot of 3 color(Y=3 classes), input data will be the points on the axis\n",
    "\n",
    "\n",
    "\n",
    "- X: 300x2\n",
    "- Y: 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ec7ac0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(seed=1984):\n",
    "    np.random.seed(seed)\n",
    "    N = 100\n",
    "    DIM = 2\n",
    "    CLS_NUM = 3\n",
    "    \n",
    "    x = np.zeros((N * CLS_NUM, DIM))\n",
    "    t = np.zeros((N * CLS_NUM, CLS_NUM), dtype=np.int)\n",
    "    \n",
    "    \n",
    "    for j in range(CLS_NUM):\n",
    "        for i in range(N):  # means N * CLS_NUMS\n",
    "            rate = i / N\n",
    "            radius = 1.0 * rate\n",
    "            theta = (4.0 * j) + (4.0 * rate) + (0.2 * np.random.randn())\n",
    "            \n",
    "            ix = N*j + i\n",
    "            x[ix] = np.array([radius * np.sin(theta), radius * np.cos(theta)]).flatten()\n",
    "            t[ix, j] = 1\n",
    "    \n",
    "    return x,t    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f7414fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: (300, 2)\n",
      "t: (300, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create the dataset and plot the graph\n",
    "\n",
    "x, t = load_data()\n",
    "print(\"x: {}\".format(x.shape))\n",
    "print(\"t: {}\".format(t.shape))\n",
    "\n",
    "plt.scatter(x[:,0], x[:,1], color=t)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e055dfa",
   "metadata": {},
   "source": [
    "## 1.2 Custom dataset, split and Dataloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5567208d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a custom dataset for the data loader\n",
    "\n",
    "\n",
    "class spiralDataset(torch.utils.data.Dataset):\n",
    "    \"\"\" Spiral classification dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, x, t):\n",
    "        self.x = x\n",
    "        self.t = t\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "        x = self.x[index,:]\n",
    "        t = self.t[index,:].argmax()\n",
    "        return x, t\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(x)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ab5b0362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([-0., 0.]), tensor(0))\n"
     ]
    }
   ],
   "source": [
    "# Create dataset and print the first output\n",
    "\n",
    "x_tensor = torch.Tensor(x)\n",
    "t_tensor = torch.Tensor(t)\n",
    "dataset_spiral = spiralDataset(x_tensor,t_tensor)\n",
    "print(dataset_spiral[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02edccae",
   "metadata": {},
   "source": [
    "For this example, we will use a 80%-20% split for the train and validation set\n",
    "\n",
    "At the end, we will regenerate another 300 sample for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f81d2da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training example: 240\n",
      "Number of validation example: 60\n"
     ]
    }
   ],
   "source": [
    "# split dataset\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "train_data, valid_data = torch.utils.data.random_split(dataset_spiral, [240, 60])\n",
    "\n",
    "print('Number of training example: {}'.format(len(train_data)))\n",
    "print('Number of validation example: {}'.format(len(valid_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cc747500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset distribution:\n",
      "{0: 79, 1: 80, 2: 81}\n",
      "Validation dataset distribution:\n",
      "{0: 21, 1: 20, 2: 19}\n"
     ]
    }
   ],
   "source": [
    "# check the distrubution in the data\n",
    "def checkclass(dataset):\n",
    "    dic = {0: 0,\n",
    "           1: 0,\n",
    "           2: 0}\n",
    "    for i in range(len(dataset)):\n",
    "        _,cls_num = dataset[i]\n",
    "        if cls_num == 0:\n",
    "            dic[0] += 1\n",
    "        if cls_num == 1:\n",
    "            dic[1] += 1\n",
    "        if cls_num == 2:\n",
    "            dic[2] += 1\n",
    "    return dic\n",
    "\n",
    "print('Train dataset distribution:')\n",
    "print(checkclass(train_data))\n",
    "print('Validation dataset distribution:')\n",
    "print(checkclass(valid_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e5bc17",
   "metadata": {},
   "source": [
    "From the result, we can see that it is quite evenly distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "101d347e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "batch_size = 30\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=valid_data,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cf01b6",
   "metadata": {},
   "source": [
    "## 1.3 Model sturcture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b814df7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(TwoLayerNN, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        \n",
    "        # Default Pytorch layer is initialized with a normal distribution\n",
    "        self.hidden_layer = nn.Linear(input_dim, hidden_dim)\n",
    "        # nn.init.xavier_normal_(self.hidden_layer.weight)  \n",
    "        # Xavier Initialization: UNIFORM between +- sqrt(6 / (n_input + n_output))\n",
    "        nn.init.kaiming_normal_(self.hidden_layer.weight) # He Initialization: NORMAL with std sqrt(2/n_input)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        \n",
    "        self.output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "        self.batchnorm = nn.BatchNorm1d(num_features=hidden_dim)\n",
    "        \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        out = self.hidden_layer(inputs)\n",
    "        out = self.batchnorm(out)\n",
    "        out = self.sigmoid(out)\n",
    "        out = self.dropout(out)\n",
    "            \n",
    "        out = self.output_layer(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3bedefea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 83 parameters\n"
     ]
    }
   ],
   "source": [
    "hidden_dim = 10\n",
    "output_dim = 3\n",
    "input_dim = 2\n",
    "lr = 1\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = TwoLayerNN(input_dim, hidden_dim, output_dim).to(device)\n",
    "\n",
    "n_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"The model has {} parameters\".format(n_params))\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baf5368",
   "metadata": {},
   "source": [
    "## 1.4 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "eac5a6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_accuracy(mode, loader, model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for x, t in loader:\n",
    "            x = x.reshape(-1,2).to(device)\n",
    "            t = t.to(device)\n",
    "            outputs = model(x)\n",
    "            _, pred = torch.max(outputs.data, 1)\n",
    "            total += t.size(0)\n",
    "            correct += (pred == t).sum().item()\n",
    "            \n",
    "    acc = 100 * correct / total\n",
    "    print('Accuracy of the network on {} set: {:.4f} %'.format(mode, acc))\n",
    "    model.train()\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "83f2bc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on train set: 33.3333 %\n",
      "Accuracy of the network on valid set: 33.3333 %\n",
      "\n",
      "New epoch, epoch 1 / 200\n",
      "Epoch [1/200], Step [1/8], Loss: 1.1487\n",
      "Epoch [1/200], Step [2/8], Loss: 1.1147\n",
      "Epoch [1/200], Step [3/8], Loss: 1.1010\n",
      "Epoch [1/200], Step [4/8], Loss: 1.1409\n",
      "Epoch [1/200], Step [5/8], Loss: 0.9614\n",
      "Epoch [1/200], Step [6/8], Loss: 1.0681\n",
      "Epoch [1/200], Step [7/8], Loss: 0.9860\n",
      "Epoch [1/200], Step [8/8], Loss: 0.9538\n",
      "Accuracy of the network on train set: 58.3333 %\n",
      "Accuracy of the network on valid set: 65.0000 %\n",
      "Best validation accuracy so far: 65.0000, at epoch 1\n",
      "\n",
      "New epoch, epoch 2 / 200\n",
      "Epoch [2/200], Step [1/8], Loss: 1.0383\n",
      "Epoch [2/200], Step [2/8], Loss: 1.1199\n",
      "Epoch [2/200], Step [3/8], Loss: 1.1514\n",
      "Epoch [2/200], Step [4/8], Loss: 0.9817\n",
      "Epoch [2/200], Step [5/8], Loss: 0.9207\n",
      "Epoch [2/200], Step [6/8], Loss: 0.9915\n",
      "Epoch [2/200], Step [7/8], Loss: 0.8737\n",
      "Epoch [2/200], Step [8/8], Loss: 0.9373\n",
      "Accuracy of the network on train set: 58.7500 %\n",
      "Accuracy of the network on valid set: 63.3333 %\n",
      "Best validation accuracy so far: 65.0000, at epoch 1\n",
      "\n",
      "New epoch, epoch 3 / 200\n",
      "Epoch [3/200], Step [1/8], Loss: 0.8796\n",
      "Epoch [3/200], Step [2/8], Loss: 0.9277\n",
      "Epoch [3/200], Step [3/8], Loss: 0.8671\n",
      "Epoch [3/200], Step [4/8], Loss: 0.8309\n",
      "Epoch [3/200], Step [5/8], Loss: 1.0123\n",
      "Epoch [3/200], Step [6/8], Loss: 1.0352\n",
      "Epoch [3/200], Step [7/8], Loss: 0.9419\n",
      "Epoch [3/200], Step [8/8], Loss: 0.8248\n",
      "Accuracy of the network on train set: 54.5833 %\n",
      "Accuracy of the network on valid set: 61.6667 %\n",
      "Best validation accuracy so far: 65.0000, at epoch 1\n",
      "\n",
      "New epoch, epoch 4 / 200\n",
      "Epoch [4/200], Step [1/8], Loss: 0.8379\n",
      "Epoch [4/200], Step [2/8], Loss: 1.0653\n",
      "Epoch [4/200], Step [3/8], Loss: 0.7073\n",
      "Epoch [4/200], Step [4/8], Loss: 0.8105\n",
      "Epoch [4/200], Step [5/8], Loss: 0.9852\n",
      "Epoch [4/200], Step [6/8], Loss: 0.7759\n",
      "Epoch [4/200], Step [7/8], Loss: 0.9750\n",
      "Epoch [4/200], Step [8/8], Loss: 0.8837\n",
      "Accuracy of the network on train set: 59.1667 %\n",
      "Accuracy of the network on valid set: 63.3333 %\n",
      "Best validation accuracy so far: 65.0000, at epoch 1\n",
      "\n",
      "New epoch, epoch 5 / 200\n",
      "Epoch [5/200], Step [1/8], Loss: 0.7539\n",
      "Epoch [5/200], Step [2/8], Loss: 0.8116\n",
      "Epoch [5/200], Step [3/8], Loss: 0.9079\n",
      "Epoch [5/200], Step [4/8], Loss: 0.9323\n",
      "Epoch [5/200], Step [5/8], Loss: 0.9731\n",
      "Epoch [5/200], Step [6/8], Loss: 0.9661\n",
      "Epoch [5/200], Step [7/8], Loss: 1.0315\n",
      "Epoch [5/200], Step [8/8], Loss: 0.9610\n",
      "Accuracy of the network on train set: 61.6667 %\n",
      "Accuracy of the network on valid set: 65.0000 %\n",
      "Best validation accuracy so far: 65.0000, at epoch 1\n",
      "\n",
      "New epoch, epoch 6 / 200\n",
      "Epoch [6/200], Step [1/8], Loss: 0.8332\n",
      "Epoch [6/200], Step [2/8], Loss: 0.7713\n",
      "Epoch [6/200], Step [3/8], Loss: 1.0120\n",
      "Epoch [6/200], Step [4/8], Loss: 0.9039\n",
      "Epoch [6/200], Step [5/8], Loss: 0.9770\n",
      "Epoch [6/200], Step [6/8], Loss: 0.7938\n",
      "Epoch [6/200], Step [7/8], Loss: 0.8016\n",
      "Epoch [6/200], Step [8/8], Loss: 1.0417\n",
      "Accuracy of the network on train set: 53.3333 %\n",
      "Accuracy of the network on valid set: 60.0000 %\n",
      "Best validation accuracy so far: 65.0000, at epoch 1\n",
      "\n",
      "New epoch, epoch 7 / 200\n",
      "Epoch [7/200], Step [1/8], Loss: 1.0718\n",
      "Epoch [7/200], Step [2/8], Loss: 0.9742\n",
      "Epoch [7/200], Step [3/8], Loss: 0.7536\n",
      "Epoch [7/200], Step [4/8], Loss: 0.9813\n",
      "Epoch [7/200], Step [5/8], Loss: 0.7883\n",
      "Epoch [7/200], Step [6/8], Loss: 0.9342\n",
      "Epoch [7/200], Step [7/8], Loss: 0.7958\n",
      "Epoch [7/200], Step [8/8], Loss: 0.8687\n",
      "Accuracy of the network on train set: 57.9167 %\n",
      "Accuracy of the network on valid set: 65.0000 %\n",
      "Best validation accuracy so far: 65.0000, at epoch 1\n",
      "\n",
      "New epoch, epoch 8 / 200\n",
      "Epoch [8/200], Step [1/8], Loss: 0.8912\n",
      "Epoch [8/200], Step [2/8], Loss: 0.7323\n",
      "Epoch [8/200], Step [3/8], Loss: 0.9911\n",
      "Epoch [8/200], Step [4/8], Loss: 0.9509\n",
      "Epoch [8/200], Step [5/8], Loss: 1.1076\n",
      "Epoch [8/200], Step [6/8], Loss: 1.0798\n",
      "Epoch [8/200], Step [7/8], Loss: 0.7663\n",
      "Epoch [8/200], Step [8/8], Loss: 1.1822\n",
      "Accuracy of the network on train set: 53.7500 %\n",
      "Accuracy of the network on valid set: 63.3333 %\n",
      "Best validation accuracy so far: 65.0000, at epoch 1\n",
      "\n",
      "New epoch, epoch 9 / 200\n",
      "Epoch [9/200], Step [1/8], Loss: 0.9343\n",
      "Epoch [9/200], Step [2/8], Loss: 0.8623\n",
      "Epoch [9/200], Step [3/8], Loss: 0.8221\n",
      "Epoch [9/200], Step [4/8], Loss: 0.8609\n",
      "Epoch [9/200], Step [5/8], Loss: 0.8244\n",
      "Epoch [9/200], Step [6/8], Loss: 0.8285\n",
      "Epoch [9/200], Step [7/8], Loss: 0.7618\n",
      "Epoch [9/200], Step [8/8], Loss: 0.8675\n",
      "Accuracy of the network on train set: 53.3333 %\n",
      "Accuracy of the network on valid set: 60.0000 %\n",
      "Best validation accuracy so far: 65.0000, at epoch 1\n",
      "\n",
      "New epoch, epoch 10 / 200\n",
      "Epoch [10/200], Step [1/8], Loss: 0.8783\n",
      "Epoch [10/200], Step [2/8], Loss: 0.9171\n",
      "Epoch [10/200], Step [3/8], Loss: 0.8718\n",
      "Epoch [10/200], Step [4/8], Loss: 0.8926\n",
      "Epoch [10/200], Step [5/8], Loss: 0.8804\n",
      "Epoch [10/200], Step [6/8], Loss: 0.7197\n",
      "Epoch [10/200], Step [7/8], Loss: 0.8526\n",
      "Epoch [10/200], Step [8/8], Loss: 1.0153\n",
      "Accuracy of the network on train set: 61.2500 %\n",
      "Accuracy of the network on valid set: 61.6667 %\n",
      "Best validation accuracy so far: 65.0000, at epoch 1\n",
      "\n",
      "New epoch, epoch 11 / 200\n",
      "Epoch [11/200], Step [1/8], Loss: 0.8530\n",
      "Epoch [11/200], Step [2/8], Loss: 1.0261\n",
      "Epoch [11/200], Step [3/8], Loss: 0.6946\n",
      "Epoch [11/200], Step [4/8], Loss: 0.9331\n",
      "Epoch [11/200], Step [5/8], Loss: 0.8186\n",
      "Epoch [11/200], Step [6/8], Loss: 0.8351\n",
      "Epoch [11/200], Step [7/8], Loss: 0.9535\n",
      "Epoch [11/200], Step [8/8], Loss: 0.7617\n",
      "Accuracy of the network on train set: 56.2500 %\n",
      "Accuracy of the network on valid set: 56.6667 %\n",
      "Best validation accuracy so far: 65.0000, at epoch 1\n",
      "\n",
      "New epoch, epoch 12 / 200\n",
      "Epoch [12/200], Step [1/8], Loss: 0.8335\n",
      "Epoch [12/200], Step [2/8], Loss: 0.8580\n",
      "Epoch [12/200], Step [3/8], Loss: 0.8565\n",
      "Epoch [12/200], Step [4/8], Loss: 1.0927\n",
      "Epoch [12/200], Step [5/8], Loss: 0.8857\n",
      "Epoch [12/200], Step [6/8], Loss: 0.9217\n",
      "Epoch [12/200], Step [7/8], Loss: 0.8447\n",
      "Epoch [12/200], Step [8/8], Loss: 0.7359\n",
      "Accuracy of the network on train set: 58.3333 %\n",
      "Accuracy of the network on valid set: 65.0000 %\n",
      "Best validation accuracy so far: 65.0000, at epoch 1\n",
      "\n",
      "New epoch, epoch 13 / 200\n",
      "Epoch [13/200], Step [1/8], Loss: 0.8147\n",
      "Epoch [13/200], Step [2/8], Loss: 0.7615\n",
      "Epoch [13/200], Step [3/8], Loss: 0.7605\n",
      "Epoch [13/200], Step [4/8], Loss: 0.9541\n",
      "Epoch [13/200], Step [5/8], Loss: 0.7923\n",
      "Epoch [13/200], Step [6/8], Loss: 0.7496\n",
      "Epoch [13/200], Step [7/8], Loss: 0.6723\n",
      "Epoch [13/200], Step [8/8], Loss: 1.0933\n",
      "Accuracy of the network on train set: 57.9167 %\n",
      "Accuracy of the network on valid set: 60.0000 %\n",
      "Best validation accuracy so far: 65.0000, at epoch 1\n",
      "\n",
      "New epoch, epoch 14 / 200\n",
      "Epoch [14/200], Step [1/8], Loss: 0.8599\n",
      "Epoch [14/200], Step [2/8], Loss: 0.8662\n",
      "Epoch [14/200], Step [3/8], Loss: 0.9287\n",
      "Epoch [14/200], Step [4/8], Loss: 0.9753\n",
      "Epoch [14/200], Step [5/8], Loss: 0.7134\n",
      "Epoch [14/200], Step [6/8], Loss: 0.8366\n",
      "Epoch [14/200], Step [7/8], Loss: 0.8765\n",
      "Epoch [14/200], Step [8/8], Loss: 0.6693\n",
      "Accuracy of the network on train set: 55.0000 %\n",
      "Accuracy of the network on valid set: 60.0000 %\n",
      "Best validation accuracy so far: 65.0000, at epoch 1\n",
      "\n",
      "New epoch, epoch 15 / 200\n",
      "Epoch [15/200], Step [1/8], Loss: 0.8740\n",
      "Epoch [15/200], Step [2/8], Loss: 0.9513\n",
      "Epoch [15/200], Step [3/8], Loss: 0.7011\n",
      "Epoch [15/200], Step [4/8], Loss: 0.8491\n",
      "Epoch [15/200], Step [5/8], Loss: 0.7886\n",
      "Epoch [15/200], Step [6/8], Loss: 0.8138\n",
      "Epoch [15/200], Step [7/8], Loss: 0.9686\n",
      "Epoch [15/200], Step [8/8], Loss: 0.8818\n",
      "Accuracy of the network on train set: 53.3333 %\n",
      "Accuracy of the network on valid set: 61.6667 %\n",
      "Best validation accuracy so far: 65.0000, at epoch 1\n",
      "\n",
      "New epoch, epoch 16 / 200\n",
      "Epoch [16/200], Step [1/8], Loss: 1.0160\n",
      "Epoch [16/200], Step [2/8], Loss: 0.8657\n",
      "Epoch [16/200], Step [3/8], Loss: 1.0796\n",
      "Epoch [16/200], Step [4/8], Loss: 0.7634\n",
      "Epoch [16/200], Step [5/8], Loss: 1.0000\n",
      "Epoch [16/200], Step [6/8], Loss: 0.8613\n",
      "Epoch [16/200], Step [7/8], Loss: 0.9984\n",
      "Epoch [16/200], Step [8/8], Loss: 0.6544\n",
      "Accuracy of the network on train set: 59.1667 %\n",
      "Accuracy of the network on valid set: 63.3333 %\n",
      "Best validation accuracy so far: 65.0000, at epoch 1\n",
      "\n",
      "New epoch, epoch 17 / 200\n",
      "Epoch [17/200], Step [1/8], Loss: 0.7944\n",
      "Epoch [17/200], Step [2/8], Loss: 0.9287\n",
      "Epoch [17/200], Step [3/8], Loss: 0.6724\n",
      "Epoch [17/200], Step [4/8], Loss: 0.9284\n",
      "Epoch [17/200], Step [5/8], Loss: 0.7920\n",
      "Epoch [17/200], Step [6/8], Loss: 0.7895\n",
      "Epoch [17/200], Step [7/8], Loss: 0.9435\n",
      "Epoch [17/200], Step [8/8], Loss: 0.7847\n",
      "Accuracy of the network on train set: 54.5833 %\n",
      "Accuracy of the network on valid set: 58.3333 %\n",
      "Best validation accuracy so far: 65.0000, at epoch 1\n",
      "\n",
      "New epoch, epoch 18 / 200\n",
      "Epoch [18/200], Step [1/8], Loss: 0.7988\n",
      "Epoch [18/200], Step [2/8], Loss: 0.8415\n",
      "Epoch [18/200], Step [3/8], Loss: 0.5925\n",
      "Epoch [18/200], Step [4/8], Loss: 0.8052\n",
      "Epoch [18/200], Step [5/8], Loss: 0.8319\n",
      "Epoch [18/200], Step [6/8], Loss: 0.8863\n",
      "Epoch [18/200], Step [7/8], Loss: 0.7835\n",
      "Epoch [18/200], Step [8/8], Loss: 0.8229\n",
      "Accuracy of the network on train set: 54.1667 %\n",
      "Accuracy of the network on valid set: 66.6667 %\n",
      "Best validation accuracy so far: 66.6667, at epoch 18\n",
      "\n",
      "New epoch, epoch 19 / 200\n",
      "Epoch [19/200], Step [1/8], Loss: 0.6227\n",
      "Epoch [19/200], Step [2/8], Loss: 0.7317\n",
      "Epoch [19/200], Step [3/8], Loss: 1.0587\n",
      "Epoch [19/200], Step [4/8], Loss: 0.8138\n",
      "Epoch [19/200], Step [5/8], Loss: 0.9677\n",
      "Epoch [19/200], Step [6/8], Loss: 0.9238\n",
      "Epoch [19/200], Step [7/8], Loss: 0.9173\n",
      "Epoch [19/200], Step [8/8], Loss: 0.8317\n",
      "Accuracy of the network on train set: 60.0000 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on valid set: 61.6667 %\n",
      "Best validation accuracy so far: 66.6667, at epoch 18\n",
      "\n",
      "New epoch, epoch 20 / 200\n",
      "Epoch [20/200], Step [1/8], Loss: 1.0208\n",
      "Epoch [20/200], Step [2/8], Loss: 0.8757\n",
      "Epoch [20/200], Step [3/8], Loss: 0.7890\n",
      "Epoch [20/200], Step [4/8], Loss: 0.7060\n",
      "Epoch [20/200], Step [5/8], Loss: 0.8511\n",
      "Epoch [20/200], Step [6/8], Loss: 0.7623\n",
      "Epoch [20/200], Step [7/8], Loss: 0.8708\n",
      "Epoch [20/200], Step [8/8], Loss: 0.9273\n",
      "Accuracy of the network on train set: 63.3333 %\n",
      "Accuracy of the network on valid set: 65.0000 %\n",
      "Best validation accuracy so far: 66.6667, at epoch 18\n",
      "\n",
      "New epoch, epoch 21 / 200\n",
      "Epoch [21/200], Step [1/8], Loss: 0.8116\n",
      "Epoch [21/200], Step [2/8], Loss: 0.9863\n",
      "Epoch [21/200], Step [3/8], Loss: 0.6695\n",
      "Epoch [21/200], Step [4/8], Loss: 0.9165\n",
      "Epoch [21/200], Step [5/8], Loss: 0.8888\n",
      "Epoch [21/200], Step [6/8], Loss: 0.6401\n",
      "Epoch [21/200], Step [7/8], Loss: 0.8150\n",
      "Epoch [21/200], Step [8/8], Loss: 0.7319\n",
      "Accuracy of the network on train set: 54.1667 %\n",
      "Accuracy of the network on valid set: 63.3333 %\n",
      "Best validation accuracy so far: 66.6667, at epoch 18\n",
      "\n",
      "New epoch, epoch 22 / 200\n",
      "Epoch [22/200], Step [1/8], Loss: 0.9487\n",
      "Epoch [22/200], Step [2/8], Loss: 0.9042\n",
      "Epoch [22/200], Step [3/8], Loss: 0.7990\n",
      "Epoch [22/200], Step [4/8], Loss: 0.7080\n",
      "Epoch [22/200], Step [5/8], Loss: 0.7904\n",
      "Epoch [22/200], Step [6/8], Loss: 1.1118\n",
      "Epoch [22/200], Step [7/8], Loss: 0.8611\n",
      "Epoch [22/200], Step [8/8], Loss: 0.7222\n",
      "Accuracy of the network on train set: 55.8333 %\n",
      "Accuracy of the network on valid set: 66.6667 %\n",
      "Best validation accuracy so far: 66.6667, at epoch 18\n",
      "\n",
      "New epoch, epoch 23 / 200\n",
      "Epoch [23/200], Step [1/8], Loss: 0.8593\n",
      "Epoch [23/200], Step [2/8], Loss: 0.7831\n",
      "Epoch [23/200], Step [3/8], Loss: 0.8225\n",
      "Epoch [23/200], Step [4/8], Loss: 0.7525\n",
      "Epoch [23/200], Step [5/8], Loss: 0.9822\n",
      "Epoch [23/200], Step [6/8], Loss: 0.7681\n",
      "Epoch [23/200], Step [7/8], Loss: 0.8252\n",
      "Epoch [23/200], Step [8/8], Loss: 0.7157\n",
      "Accuracy of the network on train set: 54.1667 %\n",
      "Accuracy of the network on valid set: 63.3333 %\n",
      "Best validation accuracy so far: 66.6667, at epoch 18\n",
      "\n",
      "New epoch, epoch 24 / 200\n",
      "Epoch [24/200], Step [1/8], Loss: 0.7465\n",
      "Epoch [24/200], Step [2/8], Loss: 0.8525\n",
      "Epoch [24/200], Step [3/8], Loss: 0.6569\n",
      "Epoch [24/200], Step [4/8], Loss: 0.7474\n",
      "Epoch [24/200], Step [5/8], Loss: 0.9789\n",
      "Epoch [24/200], Step [6/8], Loss: 0.8030\n",
      "Epoch [24/200], Step [7/8], Loss: 0.6954\n",
      "Epoch [24/200], Step [8/8], Loss: 1.1209\n",
      "Accuracy of the network on train set: 65.0000 %\n",
      "Accuracy of the network on valid set: 66.6667 %\n",
      "Best validation accuracy so far: 66.6667, at epoch 18\n",
      "\n",
      "New epoch, epoch 25 / 200\n",
      "Epoch [25/200], Step [1/8], Loss: 1.0720\n",
      "Epoch [25/200], Step [2/8], Loss: 0.7800\n",
      "Epoch [25/200], Step [3/8], Loss: 0.7343\n",
      "Epoch [25/200], Step [4/8], Loss: 0.9244\n",
      "Epoch [25/200], Step [5/8], Loss: 0.6391\n",
      "Epoch [25/200], Step [6/8], Loss: 0.7670\n",
      "Epoch [25/200], Step [7/8], Loss: 0.8145\n",
      "Epoch [25/200], Step [8/8], Loss: 0.8407\n",
      "Accuracy of the network on train set: 52.9167 %\n",
      "Accuracy of the network on valid set: 60.0000 %\n",
      "Best validation accuracy so far: 66.6667, at epoch 18\n",
      "\n",
      "New epoch, epoch 26 / 200\n",
      "Epoch [26/200], Step [1/8], Loss: 0.7864\n",
      "Epoch [26/200], Step [2/8], Loss: 0.7028\n",
      "Epoch [26/200], Step [3/8], Loss: 0.8981\n",
      "Epoch [26/200], Step [4/8], Loss: 0.8382\n",
      "Epoch [26/200], Step [5/8], Loss: 0.8604\n",
      "Epoch [26/200], Step [6/8], Loss: 0.8269\n",
      "Epoch [26/200], Step [7/8], Loss: 0.8666\n",
      "Epoch [26/200], Step [8/8], Loss: 0.7159\n",
      "Accuracy of the network on train set: 57.0833 %\n",
      "Accuracy of the network on valid set: 65.0000 %\n",
      "Best validation accuracy so far: 66.6667, at epoch 18\n",
      "\n",
      "New epoch, epoch 27 / 200\n",
      "Epoch [27/200], Step [1/8], Loss: 0.7236\n",
      "Epoch [27/200], Step [2/8], Loss: 0.6460\n",
      "Epoch [27/200], Step [3/8], Loss: 0.9181\n",
      "Epoch [27/200], Step [4/8], Loss: 1.1422\n",
      "Epoch [27/200], Step [5/8], Loss: 0.7447\n",
      "Epoch [27/200], Step [6/8], Loss: 1.0487\n",
      "Epoch [27/200], Step [7/8], Loss: 0.8904\n",
      "Epoch [27/200], Step [8/8], Loss: 0.6876\n",
      "Accuracy of the network on train set: 54.5833 %\n",
      "Accuracy of the network on valid set: 68.3333 %\n",
      "Best validation accuracy so far: 68.3333, at epoch 27\n",
      "\n",
      "New epoch, epoch 28 / 200\n",
      "Epoch [28/200], Step [1/8], Loss: 0.7521\n",
      "Epoch [28/200], Step [2/8], Loss: 0.8374\n",
      "Epoch [28/200], Step [3/8], Loss: 0.8351\n",
      "Epoch [28/200], Step [4/8], Loss: 0.7940\n",
      "Epoch [28/200], Step [5/8], Loss: 0.8077\n",
      "Epoch [28/200], Step [6/8], Loss: 1.1094\n",
      "Epoch [28/200], Step [7/8], Loss: 0.7147\n",
      "Epoch [28/200], Step [8/8], Loss: 0.7760\n",
      "Accuracy of the network on train set: 55.0000 %\n",
      "Accuracy of the network on valid set: 63.3333 %\n",
      "Best validation accuracy so far: 68.3333, at epoch 27\n",
      "\n",
      "New epoch, epoch 29 / 200\n",
      "Epoch [29/200], Step [1/8], Loss: 0.6854\n",
      "Epoch [29/200], Step [2/8], Loss: 0.8024\n",
      "Epoch [29/200], Step [3/8], Loss: 0.7398\n",
      "Epoch [29/200], Step [4/8], Loss: 0.7798\n",
      "Epoch [29/200], Step [5/8], Loss: 0.7912\n",
      "Epoch [29/200], Step [6/8], Loss: 0.5348\n",
      "Epoch [29/200], Step [7/8], Loss: 0.9328\n",
      "Epoch [29/200], Step [8/8], Loss: 0.8856\n",
      "Accuracy of the network on train set: 55.0000 %\n",
      "Accuracy of the network on valid set: 63.3333 %\n",
      "Best validation accuracy so far: 68.3333, at epoch 27\n",
      "\n",
      "New epoch, epoch 30 / 200\n",
      "Epoch [30/200], Step [1/8], Loss: 0.8986\n",
      "Epoch [30/200], Step [2/8], Loss: 0.9982\n",
      "Epoch [30/200], Step [3/8], Loss: 0.7349\n",
      "Epoch [30/200], Step [4/8], Loss: 0.8447\n",
      "Epoch [30/200], Step [5/8], Loss: 0.7299\n",
      "Epoch [30/200], Step [6/8], Loss: 0.6233\n",
      "Epoch [30/200], Step [7/8], Loss: 0.8609\n",
      "Epoch [30/200], Step [8/8], Loss: 0.7952\n",
      "Accuracy of the network on train set: 60.4167 %\n",
      "Accuracy of the network on valid set: 66.6667 %\n",
      "Best validation accuracy so far: 68.3333, at epoch 27\n",
      "\n",
      "New epoch, epoch 31 / 200\n",
      "Epoch [31/200], Step [1/8], Loss: 0.8735\n",
      "Epoch [31/200], Step [2/8], Loss: 0.8042\n",
      "Epoch [31/200], Step [3/8], Loss: 0.7508\n",
      "Epoch [31/200], Step [4/8], Loss: 0.7085\n",
      "Epoch [31/200], Step [5/8], Loss: 0.8491\n",
      "Epoch [31/200], Step [6/8], Loss: 0.8516\n",
      "Epoch [31/200], Step [7/8], Loss: 0.5531\n",
      "Epoch [31/200], Step [8/8], Loss: 0.7711\n",
      "Accuracy of the network on train set: 60.8333 %\n",
      "Accuracy of the network on valid set: 70.0000 %\n",
      "Best validation accuracy so far: 70.0000, at epoch 31\n",
      "\n",
      "New epoch, epoch 32 / 200\n",
      "Epoch [32/200], Step [1/8], Loss: 0.8915\n",
      "Epoch [32/200], Step [2/8], Loss: 1.1216\n",
      "Epoch [32/200], Step [3/8], Loss: 0.7444\n",
      "Epoch [32/200], Step [4/8], Loss: 1.0615\n",
      "Epoch [32/200], Step [5/8], Loss: 0.5579\n",
      "Epoch [32/200], Step [6/8], Loss: 0.7573\n",
      "Epoch [32/200], Step [7/8], Loss: 0.8101\n",
      "Epoch [32/200], Step [8/8], Loss: 0.7426\n",
      "Accuracy of the network on train set: 65.8333 %\n",
      "Accuracy of the network on valid set: 68.3333 %\n",
      "Best validation accuracy so far: 70.0000, at epoch 31\n",
      "\n",
      "New epoch, epoch 33 / 200\n",
      "Epoch [33/200], Step [1/8], Loss: 0.6474\n",
      "Epoch [33/200], Step [2/8], Loss: 0.6712\n",
      "Epoch [33/200], Step [3/8], Loss: 1.0490\n",
      "Epoch [33/200], Step [4/8], Loss: 0.6952\n",
      "Epoch [33/200], Step [5/8], Loss: 0.6640\n",
      "Epoch [33/200], Step [6/8], Loss: 0.9145\n",
      "Epoch [33/200], Step [7/8], Loss: 0.7139\n",
      "Epoch [33/200], Step [8/8], Loss: 0.9021\n",
      "Accuracy of the network on train set: 59.5833 %\n",
      "Accuracy of the network on valid set: 63.3333 %\n",
      "Best validation accuracy so far: 70.0000, at epoch 31\n",
      "\n",
      "New epoch, epoch 34 / 200\n",
      "Epoch [34/200], Step [1/8], Loss: 0.7994\n",
      "Epoch [34/200], Step [2/8], Loss: 0.9181\n",
      "Epoch [34/200], Step [3/8], Loss: 0.8093\n",
      "Epoch [34/200], Step [4/8], Loss: 0.5846\n",
      "Epoch [34/200], Step [5/8], Loss: 0.7380\n",
      "Epoch [34/200], Step [6/8], Loss: 0.7806\n",
      "Epoch [34/200], Step [7/8], Loss: 0.7247\n",
      "Epoch [34/200], Step [8/8], Loss: 0.9520\n",
      "Accuracy of the network on train set: 55.4167 %\n",
      "Accuracy of the network on valid set: 68.3333 %\n",
      "Best validation accuracy so far: 70.0000, at epoch 31\n",
      "\n",
      "New epoch, epoch 35 / 200\n",
      "Epoch [35/200], Step [1/8], Loss: 0.8770\n",
      "Epoch [35/200], Step [2/8], Loss: 0.6709\n",
      "Epoch [35/200], Step [3/8], Loss: 0.7934\n",
      "Epoch [35/200], Step [4/8], Loss: 0.8299\n",
      "Epoch [35/200], Step [5/8], Loss: 0.8169\n",
      "Epoch [35/200], Step [6/8], Loss: 0.7638\n",
      "Epoch [35/200], Step [7/8], Loss: 0.9463\n",
      "Epoch [35/200], Step [8/8], Loss: 0.8313\n",
      "Accuracy of the network on train set: 58.7500 %\n",
      "Accuracy of the network on valid set: 68.3333 %\n",
      "Best validation accuracy so far: 70.0000, at epoch 31\n",
      "\n",
      "New epoch, epoch 36 / 200\n",
      "Epoch [36/200], Step [1/8], Loss: 0.8044\n",
      "Epoch [36/200], Step [2/8], Loss: 0.6924\n",
      "Epoch [36/200], Step [3/8], Loss: 0.7013\n",
      "Epoch [36/200], Step [4/8], Loss: 0.7968\n",
      "Epoch [36/200], Step [5/8], Loss: 0.7396\n",
      "Epoch [36/200], Step [6/8], Loss: 0.6138\n",
      "Epoch [36/200], Step [7/8], Loss: 0.9447\n",
      "Epoch [36/200], Step [8/8], Loss: 0.8210\n",
      "Accuracy of the network on train set: 61.2500 %\n",
      "Accuracy of the network on valid set: 65.0000 %\n",
      "Best validation accuracy so far: 70.0000, at epoch 31\n",
      "\n",
      "New epoch, epoch 37 / 200\n",
      "Epoch [37/200], Step [1/8], Loss: 0.5498\n",
      "Epoch [37/200], Step [2/8], Loss: 0.8710\n",
      "Epoch [37/200], Step [3/8], Loss: 0.8640\n",
      "Epoch [37/200], Step [4/8], Loss: 0.9635\n",
      "Epoch [37/200], Step [5/8], Loss: 0.8322\n",
      "Epoch [37/200], Step [6/8], Loss: 0.8297\n",
      "Epoch [37/200], Step [7/8], Loss: 0.9019\n",
      "Epoch [37/200], Step [8/8], Loss: 0.7004\n",
      "Accuracy of the network on train set: 56.2500 %\n",
      "Accuracy of the network on valid set: 68.3333 %\n",
      "Best validation accuracy so far: 70.0000, at epoch 31\n",
      "\n",
      "New epoch, epoch 38 / 200\n",
      "Epoch [38/200], Step [1/8], Loss: 0.8039\n",
      "Epoch [38/200], Step [2/8], Loss: 0.7384\n",
      "Epoch [38/200], Step [3/8], Loss: 0.6019\n",
      "Epoch [38/200], Step [4/8], Loss: 0.7455\n",
      "Epoch [38/200], Step [5/8], Loss: 0.7574\n",
      "Epoch [38/200], Step [6/8], Loss: 0.7737\n",
      "Epoch [38/200], Step [7/8], Loss: 0.8228\n",
      "Epoch [38/200], Step [8/8], Loss: 0.8255\n",
      "Accuracy of the network on train set: 56.6667 %\n",
      "Accuracy of the network on valid set: 68.3333 %\n",
      "Best validation accuracy so far: 70.0000, at epoch 31\n",
      "\n",
      "New epoch, epoch 39 / 200\n",
      "Epoch [39/200], Step [1/8], Loss: 0.6232\n",
      "Epoch [39/200], Step [2/8], Loss: 0.6321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/200], Step [3/8], Loss: 0.8186\n",
      "Epoch [39/200], Step [4/8], Loss: 0.7950\n",
      "Epoch [39/200], Step [5/8], Loss: 0.8333\n",
      "Epoch [39/200], Step [6/8], Loss: 0.8469\n",
      "Epoch [39/200], Step [7/8], Loss: 0.9698\n",
      "Epoch [39/200], Step [8/8], Loss: 0.9083\n",
      "Accuracy of the network on train set: 58.7500 %\n",
      "Accuracy of the network on valid set: 66.6667 %\n",
      "Best validation accuracy so far: 70.0000, at epoch 31\n",
      "\n",
      "New epoch, epoch 40 / 200\n",
      "Epoch [40/200], Step [1/8], Loss: 0.8033\n",
      "Epoch [40/200], Step [2/8], Loss: 0.8219\n",
      "Epoch [40/200], Step [3/8], Loss: 0.6746\n",
      "Epoch [40/200], Step [4/8], Loss: 0.6345\n",
      "Epoch [40/200], Step [5/8], Loss: 0.8351\n",
      "Epoch [40/200], Step [6/8], Loss: 0.9217\n",
      "Epoch [40/200], Step [7/8], Loss: 0.7228\n",
      "Epoch [40/200], Step [8/8], Loss: 0.8756\n",
      "Accuracy of the network on train set: 60.0000 %\n",
      "Accuracy of the network on valid set: 65.0000 %\n",
      "Best validation accuracy so far: 70.0000, at epoch 31\n",
      "\n",
      "New epoch, epoch 41 / 200\n",
      "Epoch [41/200], Step [1/8], Loss: 0.7253\n",
      "Epoch [41/200], Step [2/8], Loss: 0.8872\n",
      "Epoch [41/200], Step [3/8], Loss: 0.9124\n",
      "Epoch [41/200], Step [4/8], Loss: 0.7388\n",
      "Epoch [41/200], Step [5/8], Loss: 0.7219\n",
      "Epoch [41/200], Step [6/8], Loss: 0.9846\n",
      "Epoch [41/200], Step [7/8], Loss: 0.6618\n",
      "Epoch [41/200], Step [8/8], Loss: 0.7592\n",
      "Accuracy of the network on train set: 59.5833 %\n",
      "Accuracy of the network on valid set: 65.0000 %\n",
      "Best validation accuracy so far: 70.0000, at epoch 31\n",
      "\n",
      "New epoch, epoch 42 / 200\n",
      "Epoch [42/200], Step [1/8], Loss: 0.7326\n",
      "Epoch [42/200], Step [2/8], Loss: 0.8194\n",
      "Epoch [42/200], Step [3/8], Loss: 0.8660\n",
      "Epoch [42/200], Step [4/8], Loss: 0.8991\n",
      "Epoch [42/200], Step [5/8], Loss: 0.7712\n",
      "Epoch [42/200], Step [6/8], Loss: 0.7185\n",
      "Epoch [42/200], Step [7/8], Loss: 0.9002\n",
      "Epoch [42/200], Step [8/8], Loss: 0.6641\n",
      "Accuracy of the network on train set: 55.8333 %\n",
      "Accuracy of the network on valid set: 65.0000 %\n",
      "Best validation accuracy so far: 70.0000, at epoch 31\n",
      "\n",
      "New epoch, epoch 43 / 200\n",
      "Epoch [43/200], Step [1/8], Loss: 0.5519\n",
      "Epoch [43/200], Step [2/8], Loss: 0.7258\n",
      "Epoch [43/200], Step [3/8], Loss: 0.7466\n",
      "Epoch [43/200], Step [4/8], Loss: 0.7489\n",
      "Epoch [43/200], Step [5/8], Loss: 0.5949\n",
      "Epoch [43/200], Step [6/8], Loss: 1.0928\n",
      "Epoch [43/200], Step [7/8], Loss: 0.8968\n",
      "Epoch [43/200], Step [8/8], Loss: 0.8774\n",
      "Accuracy of the network on train set: 57.0833 %\n",
      "Accuracy of the network on valid set: 68.3333 %\n",
      "Best validation accuracy so far: 70.0000, at epoch 31\n",
      "\n",
      "New epoch, epoch 44 / 200\n",
      "Epoch [44/200], Step [1/8], Loss: 0.7354\n",
      "Epoch [44/200], Step [2/8], Loss: 0.7851\n",
      "Epoch [44/200], Step [3/8], Loss: 0.7011\n",
      "Epoch [44/200], Step [4/8], Loss: 0.8010\n",
      "Epoch [44/200], Step [5/8], Loss: 0.9173\n",
      "Epoch [44/200], Step [6/8], Loss: 0.7480\n",
      "Epoch [44/200], Step [7/8], Loss: 0.7034\n",
      "Epoch [44/200], Step [8/8], Loss: 0.6287\n",
      "Accuracy of the network on train set: 58.3333 %\n",
      "Accuracy of the network on valid set: 66.6667 %\n",
      "Best validation accuracy so far: 70.0000, at epoch 31\n",
      "\n",
      "New epoch, epoch 45 / 200\n",
      "Epoch [45/200], Step [1/8], Loss: 0.7232\n",
      "Epoch [45/200], Step [2/8], Loss: 0.6858\n",
      "Epoch [45/200], Step [3/8], Loss: 0.5631\n",
      "Epoch [45/200], Step [4/8], Loss: 0.8792\n",
      "Epoch [45/200], Step [5/8], Loss: 0.7760\n",
      "Epoch [45/200], Step [6/8], Loss: 0.7348\n",
      "Epoch [45/200], Step [7/8], Loss: 0.9269\n",
      "Epoch [45/200], Step [8/8], Loss: 0.8985\n",
      "Accuracy of the network on train set: 60.4167 %\n",
      "Accuracy of the network on valid set: 68.3333 %\n",
      "Best validation accuracy so far: 70.0000, at epoch 31\n",
      "\n",
      "New epoch, epoch 46 / 200\n",
      "Epoch [46/200], Step [1/8], Loss: 0.7962\n",
      "Epoch [46/200], Step [2/8], Loss: 0.6882\n",
      "Epoch [46/200], Step [3/8], Loss: 0.6941\n",
      "Epoch [46/200], Step [4/8], Loss: 0.9276\n",
      "Epoch [46/200], Step [5/8], Loss: 0.7611\n",
      "Epoch [46/200], Step [6/8], Loss: 0.6240\n",
      "Epoch [46/200], Step [7/8], Loss: 0.6961\n",
      "Epoch [46/200], Step [8/8], Loss: 0.8755\n",
      "Accuracy of the network on train set: 63.7500 %\n",
      "Accuracy of the network on valid set: 66.6667 %\n",
      "Best validation accuracy so far: 70.0000, at epoch 31\n",
      "\n",
      "New epoch, epoch 47 / 200\n",
      "Epoch [47/200], Step [1/8], Loss: 0.8423\n",
      "Epoch [47/200], Step [2/8], Loss: 0.7799\n",
      "Epoch [47/200], Step [3/8], Loss: 0.7686\n",
      "Epoch [47/200], Step [4/8], Loss: 0.7796\n",
      "Epoch [47/200], Step [5/8], Loss: 0.6638\n",
      "Epoch [47/200], Step [6/8], Loss: 0.8912\n",
      "Epoch [47/200], Step [7/8], Loss: 0.5913\n",
      "Epoch [47/200], Step [8/8], Loss: 0.7918\n",
      "Accuracy of the network on train set: 64.5833 %\n",
      "Accuracy of the network on valid set: 65.0000 %\n",
      "Best validation accuracy so far: 70.0000, at epoch 31\n",
      "\n",
      "New epoch, epoch 48 / 200\n",
      "Epoch [48/200], Step [1/8], Loss: 0.6946\n",
      "Epoch [48/200], Step [2/8], Loss: 0.6529\n",
      "Epoch [48/200], Step [3/8], Loss: 0.9971\n",
      "Epoch [48/200], Step [4/8], Loss: 0.6788\n",
      "Epoch [48/200], Step [5/8], Loss: 0.6689\n",
      "Epoch [48/200], Step [6/8], Loss: 0.7660\n",
      "Epoch [48/200], Step [7/8], Loss: 0.7250\n",
      "Epoch [48/200], Step [8/8], Loss: 0.8043\n",
      "Accuracy of the network on train set: 71.2500 %\n",
      "Accuracy of the network on valid set: 70.0000 %\n",
      "Best validation accuracy so far: 70.0000, at epoch 31\n",
      "\n",
      "New epoch, epoch 49 / 200\n",
      "Epoch [49/200], Step [1/8], Loss: 0.7666\n",
      "Epoch [49/200], Step [2/8], Loss: 0.9612\n",
      "Epoch [49/200], Step [3/8], Loss: 0.8152\n",
      "Epoch [49/200], Step [4/8], Loss: 0.7061\n",
      "Epoch [49/200], Step [5/8], Loss: 0.6762\n",
      "Epoch [49/200], Step [6/8], Loss: 0.8298\n",
      "Epoch [49/200], Step [7/8], Loss: 0.6934\n",
      "Epoch [49/200], Step [8/8], Loss: 0.7003\n",
      "Accuracy of the network on train set: 58.7500 %\n",
      "Accuracy of the network on valid set: 65.0000 %\n",
      "Best validation accuracy so far: 70.0000, at epoch 31\n",
      "\n",
      "New epoch, epoch 50 / 200\n",
      "Epoch [50/200], Step [1/8], Loss: 0.6572\n",
      "Epoch [50/200], Step [2/8], Loss: 0.8943\n",
      "Epoch [50/200], Step [3/8], Loss: 0.8142\n",
      "Epoch [50/200], Step [4/8], Loss: 0.8655\n",
      "Epoch [50/200], Step [5/8], Loss: 0.8036\n",
      "Epoch [50/200], Step [6/8], Loss: 0.9230\n",
      "Epoch [50/200], Step [7/8], Loss: 0.7126\n",
      "Epoch [50/200], Step [8/8], Loss: 0.7697\n",
      "Accuracy of the network on train set: 62.5000 %\n",
      "Accuracy of the network on valid set: 68.3333 %\n",
      "Best validation accuracy so far: 70.0000, at epoch 31\n",
      "\n",
      "New epoch, epoch 51 / 200\n",
      "Epoch [51/200], Step [1/8], Loss: 0.7961\n",
      "Epoch [51/200], Step [2/8], Loss: 0.5141\n",
      "Epoch [51/200], Step [3/8], Loss: 0.9467\n",
      "Epoch [51/200], Step [4/8], Loss: 0.7471\n",
      "Epoch [51/200], Step [5/8], Loss: 0.6500\n",
      "Epoch [51/200], Step [6/8], Loss: 0.8151\n",
      "Epoch [51/200], Step [7/8], Loss: 0.7629\n",
      "Epoch [51/200], Step [8/8], Loss: 0.5975\n",
      "Accuracy of the network on train set: 60.8333 %\n",
      "Accuracy of the network on valid set: 70.0000 %\n",
      "Best validation accuracy so far: 70.0000, at epoch 31\n",
      "\n",
      "New epoch, epoch 52 / 200\n",
      "Epoch [52/200], Step [1/8], Loss: 0.6995\n",
      "Epoch [52/200], Step [2/8], Loss: 0.7662\n",
      "Epoch [52/200], Step [3/8], Loss: 0.6371\n",
      "Epoch [52/200], Step [4/8], Loss: 0.6238\n",
      "Epoch [52/200], Step [5/8], Loss: 0.5866\n",
      "Epoch [52/200], Step [6/8], Loss: 0.8213\n",
      "Epoch [52/200], Step [7/8], Loss: 0.7330\n",
      "Epoch [52/200], Step [8/8], Loss: 0.6866\n",
      "Accuracy of the network on train set: 64.1667 %\n",
      "Accuracy of the network on valid set: 73.3333 %\n",
      "Best validation accuracy so far: 73.3333, at epoch 52\n",
      "\n",
      "New epoch, epoch 53 / 200\n",
      "Epoch [53/200], Step [1/8], Loss: 0.7735\n",
      "Epoch [53/200], Step [2/8], Loss: 0.6980\n",
      "Epoch [53/200], Step [3/8], Loss: 0.6278\n",
      "Epoch [53/200], Step [4/8], Loss: 0.7385\n",
      "Epoch [53/200], Step [5/8], Loss: 0.7178\n",
      "Epoch [53/200], Step [6/8], Loss: 0.7207\n",
      "Epoch [53/200], Step [7/8], Loss: 0.6583\n",
      "Epoch [53/200], Step [8/8], Loss: 1.0496\n",
      "Accuracy of the network on train set: 60.8333 %\n",
      "Accuracy of the network on valid set: 70.0000 %\n",
      "Best validation accuracy so far: 73.3333, at epoch 52\n",
      "\n",
      "New epoch, epoch 54 / 200\n",
      "Epoch [54/200], Step [1/8], Loss: 0.6106\n",
      "Epoch [54/200], Step [2/8], Loss: 0.5943\n",
      "Epoch [54/200], Step [3/8], Loss: 0.6375\n",
      "Epoch [54/200], Step [4/8], Loss: 0.7033\n",
      "Epoch [54/200], Step [5/8], Loss: 0.8122\n",
      "Epoch [54/200], Step [6/8], Loss: 0.6808\n",
      "Epoch [54/200], Step [7/8], Loss: 0.7268\n",
      "Epoch [54/200], Step [8/8], Loss: 0.7925\n",
      "Accuracy of the network on train set: 74.1667 %\n",
      "Accuracy of the network on valid set: 71.6667 %\n",
      "Best validation accuracy so far: 73.3333, at epoch 52\n",
      "\n",
      "New epoch, epoch 55 / 200\n",
      "Epoch [55/200], Step [1/8], Loss: 0.7988\n",
      "Epoch [55/200], Step [2/8], Loss: 0.5582\n",
      "Epoch [55/200], Step [3/8], Loss: 0.8444\n",
      "Epoch [55/200], Step [4/8], Loss: 0.6940\n",
      "Epoch [55/200], Step [5/8], Loss: 0.7677\n",
      "Epoch [55/200], Step [6/8], Loss: 0.6901\n",
      "Epoch [55/200], Step [7/8], Loss: 0.7639\n",
      "Epoch [55/200], Step [8/8], Loss: 0.8694\n",
      "Accuracy of the network on train set: 64.5833 %\n",
      "Accuracy of the network on valid set: 75.0000 %\n",
      "Best validation accuracy so far: 75.0000, at epoch 55\n",
      "\n",
      "New epoch, epoch 56 / 200\n",
      "Epoch [56/200], Step [1/8], Loss: 0.8341\n",
      "Epoch [56/200], Step [2/8], Loss: 0.9871\n",
      "Epoch [56/200], Step [3/8], Loss: 0.6625\n",
      "Epoch [56/200], Step [4/8], Loss: 0.5781\n",
      "Epoch [56/200], Step [5/8], Loss: 0.7365\n",
      "Epoch [56/200], Step [6/8], Loss: 0.8084\n",
      "Epoch [56/200], Step [7/8], Loss: 0.6015\n",
      "Epoch [56/200], Step [8/8], Loss: 0.6397\n",
      "Accuracy of the network on train set: 67.5000 %\n",
      "Accuracy of the network on valid set: 75.0000 %\n",
      "Best validation accuracy so far: 75.0000, at epoch 55\n",
      "\n",
      "New epoch, epoch 57 / 200\n",
      "Epoch [57/200], Step [1/8], Loss: 0.6700\n",
      "Epoch [57/200], Step [2/8], Loss: 0.8486\n",
      "Epoch [57/200], Step [3/8], Loss: 0.7477\n",
      "Epoch [57/200], Step [4/8], Loss: 1.1902\n",
      "Epoch [57/200], Step [5/8], Loss: 0.6138\n",
      "Epoch [57/200], Step [6/8], Loss: 0.7407\n",
      "Epoch [57/200], Step [7/8], Loss: 0.6629\n",
      "Epoch [57/200], Step [8/8], Loss: 0.7382\n",
      "Accuracy of the network on train set: 70.0000 %\n",
      "Accuracy of the network on valid set: 70.0000 %\n",
      "Best validation accuracy so far: 75.0000, at epoch 55\n",
      "\n",
      "New epoch, epoch 58 / 200\n",
      "Epoch [58/200], Step [1/8], Loss: 0.7122\n",
      "Epoch [58/200], Step [2/8], Loss: 0.8122\n",
      "Epoch [58/200], Step [3/8], Loss: 0.7765\n",
      "Epoch [58/200], Step [4/8], Loss: 0.7853\n",
      "Epoch [58/200], Step [5/8], Loss: 0.7509\n",
      "Epoch [58/200], Step [6/8], Loss: 0.7808\n",
      "Epoch [58/200], Step [7/8], Loss: 0.7006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/200], Step [8/8], Loss: 0.7127\n",
      "Accuracy of the network on train set: 70.0000 %\n",
      "Accuracy of the network on valid set: 76.6667 %\n",
      "Best validation accuracy so far: 76.6667, at epoch 58\n",
      "\n",
      "New epoch, epoch 59 / 200\n",
      "Epoch [59/200], Step [1/8], Loss: 0.8562\n",
      "Epoch [59/200], Step [2/8], Loss: 0.7509\n",
      "Epoch [59/200], Step [3/8], Loss: 0.7160\n",
      "Epoch [59/200], Step [4/8], Loss: 0.5644\n",
      "Epoch [59/200], Step [5/8], Loss: 0.7521\n",
      "Epoch [59/200], Step [6/8], Loss: 0.8311\n",
      "Epoch [59/200], Step [7/8], Loss: 0.6803\n",
      "Epoch [59/200], Step [8/8], Loss: 0.7348\n",
      "Accuracy of the network on train set: 70.4167 %\n",
      "Accuracy of the network on valid set: 75.0000 %\n",
      "Best validation accuracy so far: 76.6667, at epoch 58\n",
      "\n",
      "New epoch, epoch 60 / 200\n",
      "Epoch [60/200], Step [1/8], Loss: 0.7407\n",
      "Epoch [60/200], Step [2/8], Loss: 0.8133\n",
      "Epoch [60/200], Step [3/8], Loss: 0.7832\n",
      "Epoch [60/200], Step [4/8], Loss: 0.8978\n",
      "Epoch [60/200], Step [5/8], Loss: 0.6233\n",
      "Epoch [60/200], Step [6/8], Loss: 0.7969\n",
      "Epoch [60/200], Step [7/8], Loss: 0.7132\n",
      "Epoch [60/200], Step [8/8], Loss: 0.7786\n",
      "Accuracy of the network on train set: 67.9167 %\n",
      "Accuracy of the network on valid set: 76.6667 %\n",
      "Best validation accuracy so far: 76.6667, at epoch 58\n",
      "\n",
      "New epoch, epoch 61 / 200\n",
      "Epoch [61/200], Step [1/8], Loss: 0.7007\n",
      "Epoch [61/200], Step [2/8], Loss: 0.6660\n",
      "Epoch [61/200], Step [3/8], Loss: 0.7154\n",
      "Epoch [61/200], Step [4/8], Loss: 0.7774\n",
      "Epoch [61/200], Step [5/8], Loss: 0.6808\n",
      "Epoch [61/200], Step [6/8], Loss: 0.5876\n",
      "Epoch [61/200], Step [7/8], Loss: 0.8059\n",
      "Epoch [61/200], Step [8/8], Loss: 0.7372\n",
      "Accuracy of the network on train set: 73.7500 %\n",
      "Accuracy of the network on valid set: 78.3333 %\n",
      "Best validation accuracy so far: 78.3333, at epoch 61\n",
      "\n",
      "New epoch, epoch 62 / 200\n",
      "Epoch [62/200], Step [1/8], Loss: 0.6619\n",
      "Epoch [62/200], Step [2/8], Loss: 0.6853\n",
      "Epoch [62/200], Step [3/8], Loss: 0.7226\n",
      "Epoch [62/200], Step [4/8], Loss: 0.6049\n",
      "Epoch [62/200], Step [5/8], Loss: 0.6976\n",
      "Epoch [62/200], Step [6/8], Loss: 0.6155\n",
      "Epoch [62/200], Step [7/8], Loss: 0.6575\n",
      "Epoch [62/200], Step [8/8], Loss: 0.6983\n",
      "Accuracy of the network on train set: 67.0833 %\n",
      "Accuracy of the network on valid set: 71.6667 %\n",
      "Best validation accuracy so far: 78.3333, at epoch 61\n",
      "\n",
      "New epoch, epoch 63 / 200\n",
      "Epoch [63/200], Step [1/8], Loss: 0.7079\n",
      "Epoch [63/200], Step [2/8], Loss: 0.6432\n",
      "Epoch [63/200], Step [3/8], Loss: 0.6829\n",
      "Epoch [63/200], Step [4/8], Loss: 0.6437\n",
      "Epoch [63/200], Step [5/8], Loss: 0.5492\n",
      "Epoch [63/200], Step [6/8], Loss: 0.7203\n",
      "Epoch [63/200], Step [7/8], Loss: 0.5614\n",
      "Epoch [63/200], Step [8/8], Loss: 0.7301\n",
      "Accuracy of the network on train set: 68.7500 %\n",
      "Accuracy of the network on valid set: 70.0000 %\n",
      "Best validation accuracy so far: 78.3333, at epoch 61\n",
      "\n",
      "New epoch, epoch 64 / 200\n",
      "Epoch [64/200], Step [1/8], Loss: 0.6403\n",
      "Epoch [64/200], Step [2/8], Loss: 0.6842\n",
      "Epoch [64/200], Step [3/8], Loss: 0.6349\n",
      "Epoch [64/200], Step [4/8], Loss: 0.6537\n",
      "Epoch [64/200], Step [5/8], Loss: 0.8253\n",
      "Epoch [64/200], Step [6/8], Loss: 0.7228\n",
      "Epoch [64/200], Step [7/8], Loss: 0.5289\n",
      "Epoch [64/200], Step [8/8], Loss: 0.9883\n",
      "Accuracy of the network on train set: 73.3333 %\n",
      "Accuracy of the network on valid set: 71.6667 %\n",
      "Best validation accuracy so far: 78.3333, at epoch 61\n",
      "\n",
      "New epoch, epoch 65 / 200\n",
      "Epoch [65/200], Step [1/8], Loss: 0.7011\n",
      "Epoch [65/200], Step [2/8], Loss: 0.6063\n",
      "Epoch [65/200], Step [3/8], Loss: 0.8999\n",
      "Epoch [65/200], Step [4/8], Loss: 0.5596\n",
      "Epoch [65/200], Step [5/8], Loss: 0.5082\n",
      "Epoch [65/200], Step [6/8], Loss: 0.6104\n",
      "Epoch [65/200], Step [7/8], Loss: 0.7554\n",
      "Epoch [65/200], Step [8/8], Loss: 0.7225\n",
      "Accuracy of the network on train set: 71.2500 %\n",
      "Accuracy of the network on valid set: 73.3333 %\n",
      "Best validation accuracy so far: 78.3333, at epoch 61\n",
      "\n",
      "New epoch, epoch 66 / 200\n",
      "Epoch [66/200], Step [1/8], Loss: 0.8649\n",
      "Epoch [66/200], Step [2/8], Loss: 0.6109\n",
      "Epoch [66/200], Step [3/8], Loss: 0.7179\n",
      "Epoch [66/200], Step [4/8], Loss: 0.6691\n",
      "Epoch [66/200], Step [5/8], Loss: 0.5593\n",
      "Epoch [66/200], Step [6/8], Loss: 0.6233\n",
      "Epoch [66/200], Step [7/8], Loss: 0.7653\n",
      "Epoch [66/200], Step [8/8], Loss: 0.4895\n",
      "Accuracy of the network on train set: 72.0833 %\n",
      "Accuracy of the network on valid set: 73.3333 %\n",
      "Best validation accuracy so far: 78.3333, at epoch 61\n",
      "\n",
      "New epoch, epoch 67 / 200\n",
      "Epoch [67/200], Step [1/8], Loss: 0.5726\n",
      "Epoch [67/200], Step [2/8], Loss: 0.6187\n",
      "Epoch [67/200], Step [3/8], Loss: 0.5556\n",
      "Epoch [67/200], Step [4/8], Loss: 0.5755\n",
      "Epoch [67/200], Step [5/8], Loss: 0.7918\n",
      "Epoch [67/200], Step [6/8], Loss: 0.6305\n",
      "Epoch [67/200], Step [7/8], Loss: 0.8049\n",
      "Epoch [67/200], Step [8/8], Loss: 0.5847\n",
      "Accuracy of the network on train set: 73.7500 %\n",
      "Accuracy of the network on valid set: 75.0000 %\n",
      "Best validation accuracy so far: 78.3333, at epoch 61\n",
      "\n",
      "New epoch, epoch 68 / 200\n",
      "Epoch [68/200], Step [1/8], Loss: 0.8774\n",
      "Epoch [68/200], Step [2/8], Loss: 0.6210\n",
      "Epoch [68/200], Step [3/8], Loss: 0.6193\n",
      "Epoch [68/200], Step [4/8], Loss: 0.6990\n",
      "Epoch [68/200], Step [5/8], Loss: 0.8486\n",
      "Epoch [68/200], Step [6/8], Loss: 0.5457\n",
      "Epoch [68/200], Step [7/8], Loss: 0.7453\n",
      "Epoch [68/200], Step [8/8], Loss: 0.5896\n",
      "Accuracy of the network on train set: 79.5833 %\n",
      "Accuracy of the network on valid set: 78.3333 %\n",
      "Best validation accuracy so far: 78.3333, at epoch 61\n",
      "\n",
      "New epoch, epoch 69 / 200\n",
      "Epoch [69/200], Step [1/8], Loss: 0.6902\n",
      "Epoch [69/200], Step [2/8], Loss: 0.6542\n",
      "Epoch [69/200], Step [3/8], Loss: 0.5185\n",
      "Epoch [69/200], Step [4/8], Loss: 0.6495\n",
      "Epoch [69/200], Step [5/8], Loss: 0.8227\n",
      "Epoch [69/200], Step [6/8], Loss: 0.7794\n",
      "Epoch [69/200], Step [7/8], Loss: 0.6285\n",
      "Epoch [69/200], Step [8/8], Loss: 0.6031\n",
      "Accuracy of the network on train set: 73.3333 %\n",
      "Accuracy of the network on valid set: 80.0000 %\n",
      "Best validation accuracy so far: 80.0000, at epoch 69\n",
      "\n",
      "New epoch, epoch 70 / 200\n",
      "Epoch [70/200], Step [1/8], Loss: 0.6120\n",
      "Epoch [70/200], Step [2/8], Loss: 0.6700\n",
      "Epoch [70/200], Step [3/8], Loss: 0.7473\n",
      "Epoch [70/200], Step [4/8], Loss: 0.7171\n",
      "Epoch [70/200], Step [5/8], Loss: 0.7424\n",
      "Epoch [70/200], Step [6/8], Loss: 0.8586\n",
      "Epoch [70/200], Step [7/8], Loss: 0.8050\n",
      "Epoch [70/200], Step [8/8], Loss: 0.7587\n",
      "Accuracy of the network on train set: 79.1667 %\n",
      "Accuracy of the network on valid set: 75.0000 %\n",
      "Best validation accuracy so far: 80.0000, at epoch 69\n",
      "\n",
      "New epoch, epoch 71 / 200\n",
      "Epoch [71/200], Step [1/8], Loss: 0.5894\n",
      "Epoch [71/200], Step [2/8], Loss: 0.7733\n",
      "Epoch [71/200], Step [3/8], Loss: 0.6420\n",
      "Epoch [71/200], Step [4/8], Loss: 0.6574\n",
      "Epoch [71/200], Step [5/8], Loss: 0.5568\n",
      "Epoch [71/200], Step [6/8], Loss: 0.8429\n",
      "Epoch [71/200], Step [7/8], Loss: 0.6247\n",
      "Epoch [71/200], Step [8/8], Loss: 0.7962\n",
      "Accuracy of the network on train set: 81.2500 %\n",
      "Accuracy of the network on valid set: 76.6667 %\n",
      "Best validation accuracy so far: 80.0000, at epoch 69\n",
      "\n",
      "New epoch, epoch 72 / 200\n",
      "Epoch [72/200], Step [1/8], Loss: 0.7299\n",
      "Epoch [72/200], Step [2/8], Loss: 0.6524\n",
      "Epoch [72/200], Step [3/8], Loss: 0.4696\n",
      "Epoch [72/200], Step [4/8], Loss: 0.7208\n",
      "Epoch [72/200], Step [5/8], Loss: 0.8165\n",
      "Epoch [72/200], Step [6/8], Loss: 0.6157\n",
      "Epoch [72/200], Step [7/8], Loss: 0.7338\n",
      "Epoch [72/200], Step [8/8], Loss: 0.6870\n",
      "Accuracy of the network on train set: 79.5833 %\n",
      "Accuracy of the network on valid set: 75.0000 %\n",
      "Best validation accuracy so far: 80.0000, at epoch 69\n",
      "\n",
      "New epoch, epoch 73 / 200\n",
      "Epoch [73/200], Step [1/8], Loss: 0.5833\n",
      "Epoch [73/200], Step [2/8], Loss: 0.6625\n",
      "Epoch [73/200], Step [3/8], Loss: 0.6681\n",
      "Epoch [73/200], Step [4/8], Loss: 0.8080\n",
      "Epoch [73/200], Step [5/8], Loss: 0.7541\n",
      "Epoch [73/200], Step [6/8], Loss: 0.5791\n",
      "Epoch [73/200], Step [7/8], Loss: 0.6193\n",
      "Epoch [73/200], Step [8/8], Loss: 0.6906\n",
      "Accuracy of the network on train set: 72.0833 %\n",
      "Accuracy of the network on valid set: 71.6667 %\n",
      "Best validation accuracy so far: 80.0000, at epoch 69\n",
      "\n",
      "New epoch, epoch 74 / 200\n",
      "Epoch [74/200], Step [1/8], Loss: 0.6908\n",
      "Epoch [74/200], Step [2/8], Loss: 0.4559\n",
      "Epoch [74/200], Step [3/8], Loss: 0.8890\n",
      "Epoch [74/200], Step [4/8], Loss: 0.7288\n",
      "Epoch [74/200], Step [5/8], Loss: 0.5467\n",
      "Epoch [74/200], Step [6/8], Loss: 0.4932\n",
      "Epoch [74/200], Step [7/8], Loss: 0.7243\n",
      "Epoch [74/200], Step [8/8], Loss: 0.7616\n",
      "Accuracy of the network on train set: 82.0833 %\n",
      "Accuracy of the network on valid set: 80.0000 %\n",
      "Best validation accuracy so far: 80.0000, at epoch 69\n",
      "\n",
      "New epoch, epoch 75 / 200\n",
      "Epoch [75/200], Step [1/8], Loss: 0.6283\n",
      "Epoch [75/200], Step [2/8], Loss: 0.7227\n",
      "Epoch [75/200], Step [3/8], Loss: 0.8852\n",
      "Epoch [75/200], Step [4/8], Loss: 0.5826\n",
      "Epoch [75/200], Step [5/8], Loss: 0.6606\n",
      "Epoch [75/200], Step [6/8], Loss: 0.5227\n",
      "Epoch [75/200], Step [7/8], Loss: 0.5009\n",
      "Epoch [75/200], Step [8/8], Loss: 0.6694\n",
      "Accuracy of the network on train set: 75.4167 %\n",
      "Accuracy of the network on valid set: 78.3333 %\n",
      "Best validation accuracy so far: 80.0000, at epoch 69\n",
      "\n",
      "New epoch, epoch 76 / 200\n",
      "Epoch [76/200], Step [1/8], Loss: 1.0397\n",
      "Epoch [76/200], Step [2/8], Loss: 0.7155\n",
      "Epoch [76/200], Step [3/8], Loss: 0.6238\n",
      "Epoch [76/200], Step [4/8], Loss: 0.6008\n",
      "Epoch [76/200], Step [5/8], Loss: 0.7063\n",
      "Epoch [76/200], Step [6/8], Loss: 0.6163\n",
      "Epoch [76/200], Step [7/8], Loss: 0.5905\n",
      "Epoch [76/200], Step [8/8], Loss: 0.5822\n",
      "Accuracy of the network on train set: 75.8333 %\n",
      "Accuracy of the network on valid set: 76.6667 %\n",
      "Best validation accuracy so far: 80.0000, at epoch 69\n",
      "\n",
      "New epoch, epoch 77 / 200\n",
      "Epoch [77/200], Step [1/8], Loss: 0.6129\n",
      "Epoch [77/200], Step [2/8], Loss: 0.6199\n",
      "Epoch [77/200], Step [3/8], Loss: 0.5767\n",
      "Epoch [77/200], Step [4/8], Loss: 0.6590\n",
      "Epoch [77/200], Step [5/8], Loss: 0.5982\n",
      "Epoch [77/200], Step [6/8], Loss: 0.6550\n",
      "Epoch [77/200], Step [7/8], Loss: 0.6684\n",
      "Epoch [77/200], Step [8/8], Loss: 0.8400\n",
      "Accuracy of the network on train set: 73.7500 %\n",
      "Accuracy of the network on valid set: 81.6667 %\n",
      "Best validation accuracy so far: 81.6667, at epoch 77\n",
      "\n",
      "New epoch, epoch 78 / 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [78/200], Step [1/8], Loss: 0.8030\n",
      "Epoch [78/200], Step [2/8], Loss: 0.4661\n",
      "Epoch [78/200], Step [3/8], Loss: 0.8145\n",
      "Epoch [78/200], Step [4/8], Loss: 0.5675\n",
      "Epoch [78/200], Step [5/8], Loss: 0.7544\n",
      "Epoch [78/200], Step [6/8], Loss: 0.6895\n",
      "Epoch [78/200], Step [7/8], Loss: 0.6344\n",
      "Epoch [78/200], Step [8/8], Loss: 0.5487\n",
      "Accuracy of the network on train set: 77.5000 %\n",
      "Accuracy of the network on valid set: 81.6667 %\n",
      "Best validation accuracy so far: 81.6667, at epoch 77\n",
      "\n",
      "New epoch, epoch 79 / 200\n",
      "Epoch [79/200], Step [1/8], Loss: 0.6839\n",
      "Epoch [79/200], Step [2/8], Loss: 0.7247\n",
      "Epoch [79/200], Step [3/8], Loss: 0.4659\n",
      "Epoch [79/200], Step [4/8], Loss: 0.6754\n",
      "Epoch [79/200], Step [5/8], Loss: 0.9017\n",
      "Epoch [79/200], Step [6/8], Loss: 0.6551\n",
      "Epoch [79/200], Step [7/8], Loss: 0.5281\n",
      "Epoch [79/200], Step [8/8], Loss: 0.6407\n",
      "Accuracy of the network on train set: 84.5833 %\n",
      "Accuracy of the network on valid set: 81.6667 %\n",
      "Best validation accuracy so far: 81.6667, at epoch 77\n",
      "\n",
      "New epoch, epoch 80 / 200\n",
      "Epoch [80/200], Step [1/8], Loss: 0.5913\n",
      "Epoch [80/200], Step [2/8], Loss: 0.7084\n",
      "Epoch [80/200], Step [3/8], Loss: 0.9017\n",
      "Epoch [80/200], Step [4/8], Loss: 0.6519\n",
      "Epoch [80/200], Step [5/8], Loss: 0.6956\n",
      "Epoch [80/200], Step [6/8], Loss: 0.5671\n",
      "Epoch [80/200], Step [7/8], Loss: 0.7245\n",
      "Epoch [80/200], Step [8/8], Loss: 0.7204\n",
      "Accuracy of the network on train set: 80.0000 %\n",
      "Accuracy of the network on valid set: 85.0000 %\n",
      "Best validation accuracy so far: 85.0000, at epoch 80\n",
      "\n",
      "New epoch, epoch 81 / 200\n",
      "Epoch [81/200], Step [1/8], Loss: 0.7178\n",
      "Epoch [81/200], Step [2/8], Loss: 0.4820\n",
      "Epoch [81/200], Step [3/8], Loss: 0.5591\n",
      "Epoch [81/200], Step [4/8], Loss: 0.5744\n",
      "Epoch [81/200], Step [5/8], Loss: 0.6802\n",
      "Epoch [81/200], Step [6/8], Loss: 0.6422\n",
      "Epoch [81/200], Step [7/8], Loss: 0.7793\n",
      "Epoch [81/200], Step [8/8], Loss: 0.7158\n",
      "Accuracy of the network on train set: 82.0833 %\n",
      "Accuracy of the network on valid set: 86.6667 %\n",
      "Best validation accuracy so far: 86.6667, at epoch 81\n",
      "\n",
      "New epoch, epoch 82 / 200\n",
      "Epoch [82/200], Step [1/8], Loss: 0.8021\n",
      "Epoch [82/200], Step [2/8], Loss: 0.6480\n",
      "Epoch [82/200], Step [3/8], Loss: 0.7971\n",
      "Epoch [82/200], Step [4/8], Loss: 0.5282\n",
      "Epoch [82/200], Step [5/8], Loss: 0.5598\n",
      "Epoch [82/200], Step [6/8], Loss: 0.7494\n",
      "Epoch [82/200], Step [7/8], Loss: 0.5753\n",
      "Epoch [82/200], Step [8/8], Loss: 0.6422\n",
      "Accuracy of the network on train set: 84.5833 %\n",
      "Accuracy of the network on valid set: 81.6667 %\n",
      "Best validation accuracy so far: 86.6667, at epoch 81\n",
      "\n",
      "New epoch, epoch 83 / 200\n",
      "Epoch [83/200], Step [1/8], Loss: 0.6786\n",
      "Epoch [83/200], Step [2/8], Loss: 0.8414\n",
      "Epoch [83/200], Step [3/8], Loss: 0.6225\n",
      "Epoch [83/200], Step [4/8], Loss: 0.4950\n",
      "Epoch [83/200], Step [5/8], Loss: 0.5660\n",
      "Epoch [83/200], Step [6/8], Loss: 0.9098\n",
      "Epoch [83/200], Step [7/8], Loss: 0.5951\n",
      "Epoch [83/200], Step [8/8], Loss: 0.5123\n",
      "Accuracy of the network on train set: 82.5000 %\n",
      "Accuracy of the network on valid set: 85.0000 %\n",
      "Best validation accuracy so far: 86.6667, at epoch 81\n",
      "\n",
      "New epoch, epoch 84 / 200\n",
      "Epoch [84/200], Step [1/8], Loss: 0.6503\n",
      "Epoch [84/200], Step [2/8], Loss: 0.5655\n",
      "Epoch [84/200], Step [3/8], Loss: 0.6530\n",
      "Epoch [84/200], Step [4/8], Loss: 0.6716\n",
      "Epoch [84/200], Step [5/8], Loss: 0.6135\n",
      "Epoch [84/200], Step [6/8], Loss: 1.0407\n",
      "Epoch [84/200], Step [7/8], Loss: 0.5816\n",
      "Epoch [84/200], Step [8/8], Loss: 0.8194\n",
      "Accuracy of the network on train set: 86.2500 %\n",
      "Accuracy of the network on valid set: 86.6667 %\n",
      "Best validation accuracy so far: 86.6667, at epoch 81\n",
      "\n",
      "New epoch, epoch 85 / 200\n",
      "Epoch [85/200], Step [1/8], Loss: 0.6819\n",
      "Epoch [85/200], Step [2/8], Loss: 0.6237\n",
      "Epoch [85/200], Step [3/8], Loss: 0.5254\n",
      "Epoch [85/200], Step [4/8], Loss: 0.7343\n",
      "Epoch [85/200], Step [5/8], Loss: 0.6686\n",
      "Epoch [85/200], Step [6/8], Loss: 0.6534\n",
      "Epoch [85/200], Step [7/8], Loss: 0.7449\n",
      "Epoch [85/200], Step [8/8], Loss: 0.8403\n",
      "Accuracy of the network on train set: 79.5833 %\n",
      "Accuracy of the network on valid set: 81.6667 %\n",
      "Best validation accuracy so far: 86.6667, at epoch 81\n",
      "\n",
      "New epoch, epoch 86 / 200\n",
      "Epoch [86/200], Step [1/8], Loss: 0.6761\n",
      "Epoch [86/200], Step [2/8], Loss: 0.5744\n",
      "Epoch [86/200], Step [3/8], Loss: 0.6458\n",
      "Epoch [86/200], Step [4/8], Loss: 0.5611\n",
      "Epoch [86/200], Step [5/8], Loss: 0.6451\n",
      "Epoch [86/200], Step [6/8], Loss: 0.5775\n",
      "Epoch [86/200], Step [7/8], Loss: 0.5838\n",
      "Epoch [86/200], Step [8/8], Loss: 0.5272\n",
      "Accuracy of the network on train set: 82.0833 %\n",
      "Accuracy of the network on valid set: 81.6667 %\n",
      "Best validation accuracy so far: 86.6667, at epoch 81\n",
      "\n",
      "New epoch, epoch 87 / 200\n",
      "Epoch [87/200], Step [1/8], Loss: 0.5063\n",
      "Epoch [87/200], Step [2/8], Loss: 0.4785\n",
      "Epoch [87/200], Step [3/8], Loss: 0.4757\n",
      "Epoch [87/200], Step [4/8], Loss: 0.5776\n",
      "Epoch [87/200], Step [5/8], Loss: 0.6223\n",
      "Epoch [87/200], Step [6/8], Loss: 0.6556\n",
      "Epoch [87/200], Step [7/8], Loss: 0.5527\n",
      "Epoch [87/200], Step [8/8], Loss: 0.6542\n",
      "Accuracy of the network on train set: 87.5000 %\n",
      "Accuracy of the network on valid set: 81.6667 %\n",
      "Best validation accuracy so far: 86.6667, at epoch 81\n",
      "\n",
      "New epoch, epoch 88 / 200\n",
      "Epoch [88/200], Step [1/8], Loss: 0.5146\n",
      "Epoch [88/200], Step [2/8], Loss: 0.5086\n",
      "Epoch [88/200], Step [3/8], Loss: 0.6238\n",
      "Epoch [88/200], Step [4/8], Loss: 0.5327\n",
      "Epoch [88/200], Step [5/8], Loss: 0.5759\n",
      "Epoch [88/200], Step [6/8], Loss: 0.6538\n",
      "Epoch [88/200], Step [7/8], Loss: 0.6057\n",
      "Epoch [88/200], Step [8/8], Loss: 0.7439\n",
      "Accuracy of the network on train set: 83.3333 %\n",
      "Accuracy of the network on valid set: 83.3333 %\n",
      "Best validation accuracy so far: 86.6667, at epoch 81\n",
      "\n",
      "New epoch, epoch 89 / 200\n",
      "Epoch [89/200], Step [1/8], Loss: 0.4357\n",
      "Epoch [89/200], Step [2/8], Loss: 0.6985\n",
      "Epoch [89/200], Step [3/8], Loss: 0.5356\n",
      "Epoch [89/200], Step [4/8], Loss: 0.5865\n",
      "Epoch [89/200], Step [5/8], Loss: 0.5698\n",
      "Epoch [89/200], Step [6/8], Loss: 0.5591\n",
      "Epoch [89/200], Step [7/8], Loss: 0.5473\n",
      "Epoch [89/200], Step [8/8], Loss: 0.5047\n",
      "Accuracy of the network on train set: 85.4167 %\n",
      "Accuracy of the network on valid set: 86.6667 %\n",
      "Best validation accuracy so far: 86.6667, at epoch 81\n",
      "\n",
      "New epoch, epoch 90 / 200\n",
      "Epoch [90/200], Step [1/8], Loss: 0.5572\n",
      "Epoch [90/200], Step [2/8], Loss: 0.5152\n",
      "Epoch [90/200], Step [3/8], Loss: 0.7726\n",
      "Epoch [90/200], Step [4/8], Loss: 0.5917\n",
      "Epoch [90/200], Step [5/8], Loss: 0.6788\n",
      "Epoch [90/200], Step [6/8], Loss: 0.7264\n",
      "Epoch [90/200], Step [7/8], Loss: 0.7528\n",
      "Epoch [90/200], Step [8/8], Loss: 0.8188\n",
      "Accuracy of the network on train set: 83.3333 %\n",
      "Accuracy of the network on valid set: 86.6667 %\n",
      "Best validation accuracy so far: 86.6667, at epoch 81\n",
      "\n",
      "New epoch, epoch 91 / 200\n",
      "Epoch [91/200], Step [1/8], Loss: 0.8462\n",
      "Epoch [91/200], Step [2/8], Loss: 0.5961\n",
      "Epoch [91/200], Step [3/8], Loss: 0.6011\n",
      "Epoch [91/200], Step [4/8], Loss: 0.6800\n",
      "Epoch [91/200], Step [5/8], Loss: 0.5880\n",
      "Epoch [91/200], Step [6/8], Loss: 0.6971\n",
      "Epoch [91/200], Step [7/8], Loss: 0.5164\n",
      "Epoch [91/200], Step [8/8], Loss: 0.5774\n",
      "Accuracy of the network on train set: 89.1667 %\n",
      "Accuracy of the network on valid set: 86.6667 %\n",
      "Best validation accuracy so far: 86.6667, at epoch 81\n",
      "\n",
      "New epoch, epoch 92 / 200\n",
      "Epoch [92/200], Step [1/8], Loss: 0.9137\n",
      "Epoch [92/200], Step [2/8], Loss: 0.7152\n",
      "Epoch [92/200], Step [3/8], Loss: 0.4542\n",
      "Epoch [92/200], Step [4/8], Loss: 0.5523\n",
      "Epoch [92/200], Step [5/8], Loss: 1.0119\n",
      "Epoch [92/200], Step [6/8], Loss: 0.6424\n",
      "Epoch [92/200], Step [7/8], Loss: 0.5649\n",
      "Epoch [92/200], Step [8/8], Loss: 0.5634\n",
      "Accuracy of the network on train set: 82.9167 %\n",
      "Accuracy of the network on valid set: 86.6667 %\n",
      "Best validation accuracy so far: 86.6667, at epoch 81\n",
      "\n",
      "New epoch, epoch 93 / 200\n",
      "Epoch [93/200], Step [1/8], Loss: 0.4604\n",
      "Epoch [93/200], Step [2/8], Loss: 0.7563\n",
      "Epoch [93/200], Step [3/8], Loss: 0.6517\n",
      "Epoch [93/200], Step [4/8], Loss: 0.7839\n",
      "Epoch [93/200], Step [5/8], Loss: 0.5738\n",
      "Epoch [93/200], Step [6/8], Loss: 0.6840\n",
      "Epoch [93/200], Step [7/8], Loss: 0.4368\n",
      "Epoch [93/200], Step [8/8], Loss: 0.6910\n",
      "Accuracy of the network on train set: 87.9167 %\n",
      "Accuracy of the network on valid set: 83.3333 %\n",
      "Best validation accuracy so far: 86.6667, at epoch 81\n",
      "\n",
      "New epoch, epoch 94 / 200\n",
      "Epoch [94/200], Step [1/8], Loss: 0.6192\n",
      "Epoch [94/200], Step [2/8], Loss: 0.4938\n",
      "Epoch [94/200], Step [3/8], Loss: 0.7442\n",
      "Epoch [94/200], Step [4/8], Loss: 0.8108\n",
      "Epoch [94/200], Step [5/8], Loss: 0.6968\n",
      "Epoch [94/200], Step [6/8], Loss: 0.7224\n",
      "Epoch [94/200], Step [7/8], Loss: 0.5047\n",
      "Epoch [94/200], Step [8/8], Loss: 0.7311\n",
      "Accuracy of the network on train set: 80.8333 %\n",
      "Accuracy of the network on valid set: 86.6667 %\n",
      "Best validation accuracy so far: 86.6667, at epoch 81\n",
      "\n",
      "New epoch, epoch 95 / 200\n",
      "Epoch [95/200], Step [1/8], Loss: 0.6347\n",
      "Epoch [95/200], Step [2/8], Loss: 0.7486\n",
      "Epoch [95/200], Step [3/8], Loss: 0.5583\n",
      "Epoch [95/200], Step [4/8], Loss: 0.5759\n",
      "Epoch [95/200], Step [5/8], Loss: 0.5209\n",
      "Epoch [95/200], Step [6/8], Loss: 0.6087\n",
      "Epoch [95/200], Step [7/8], Loss: 0.6570\n",
      "Epoch [95/200], Step [8/8], Loss: 0.4216\n",
      "Accuracy of the network on train set: 90.4167 %\n",
      "Accuracy of the network on valid set: 83.3333 %\n",
      "Best validation accuracy so far: 86.6667, at epoch 81\n",
      "\n",
      "New epoch, epoch 96 / 200\n",
      "Epoch [96/200], Step [1/8], Loss: 0.4148\n",
      "Epoch [96/200], Step [2/8], Loss: 0.6665\n",
      "Epoch [96/200], Step [3/8], Loss: 0.5438\n",
      "Epoch [96/200], Step [4/8], Loss: 0.7951\n",
      "Epoch [96/200], Step [5/8], Loss: 0.7317\n",
      "Epoch [96/200], Step [6/8], Loss: 0.8631\n",
      "Epoch [96/200], Step [7/8], Loss: 0.5401\n",
      "Epoch [96/200], Step [8/8], Loss: 0.6586\n",
      "Accuracy of the network on train set: 83.3333 %\n",
      "Accuracy of the network on valid set: 86.6667 %\n",
      "Best validation accuracy so far: 86.6667, at epoch 81\n",
      "\n",
      "New epoch, epoch 97 / 200\n",
      "Epoch [97/200], Step [1/8], Loss: 0.4091\n",
      "Epoch [97/200], Step [2/8], Loss: 0.5445\n",
      "Epoch [97/200], Step [3/8], Loss: 0.8953\n",
      "Epoch [97/200], Step [4/8], Loss: 0.5026\n",
      "Epoch [97/200], Step [5/8], Loss: 0.4674\n",
      "Epoch [97/200], Step [6/8], Loss: 0.6389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [97/200], Step [7/8], Loss: 0.6523\n",
      "Epoch [97/200], Step [8/8], Loss: 0.5815\n",
      "Accuracy of the network on train set: 89.1667 %\n",
      "Accuracy of the network on valid set: 85.0000 %\n",
      "Best validation accuracy so far: 86.6667, at epoch 81\n",
      "\n",
      "New epoch, epoch 98 / 200\n",
      "Epoch [98/200], Step [1/8], Loss: 0.5285\n",
      "Epoch [98/200], Step [2/8], Loss: 0.5617\n",
      "Epoch [98/200], Step [3/8], Loss: 0.7291\n",
      "Epoch [98/200], Step [4/8], Loss: 0.7923\n",
      "Epoch [98/200], Step [5/8], Loss: 0.5207\n",
      "Epoch [98/200], Step [6/8], Loss: 0.7298\n",
      "Epoch [98/200], Step [7/8], Loss: 0.5237\n",
      "Epoch [98/200], Step [8/8], Loss: 0.6867\n",
      "Accuracy of the network on train set: 87.0833 %\n",
      "Accuracy of the network on valid set: 85.0000 %\n",
      "Best validation accuracy so far: 86.6667, at epoch 81\n",
      "\n",
      "New epoch, epoch 99 / 200\n",
      "Epoch [99/200], Step [1/8], Loss: 0.6025\n",
      "Epoch [99/200], Step [2/8], Loss: 0.6005\n",
      "Epoch [99/200], Step [3/8], Loss: 0.5328\n",
      "Epoch [99/200], Step [4/8], Loss: 0.7025\n",
      "Epoch [99/200], Step [5/8], Loss: 0.7548\n",
      "Epoch [99/200], Step [6/8], Loss: 0.8372\n",
      "Epoch [99/200], Step [7/8], Loss: 0.7449\n",
      "Epoch [99/200], Step [8/8], Loss: 0.6193\n",
      "Accuracy of the network on train set: 84.5833 %\n",
      "Accuracy of the network on valid set: 81.6667 %\n",
      "Best validation accuracy so far: 86.6667, at epoch 81\n",
      "\n",
      "New epoch, epoch 100 / 200\n",
      "Epoch [100/200], Step [1/8], Loss: 0.6783\n",
      "Epoch [100/200], Step [2/8], Loss: 0.6007\n",
      "Epoch [100/200], Step [3/8], Loss: 0.6725\n",
      "Epoch [100/200], Step [4/8], Loss: 0.6669\n",
      "Epoch [100/200], Step [5/8], Loss: 0.5362\n",
      "Epoch [100/200], Step [6/8], Loss: 0.7228\n",
      "Epoch [100/200], Step [7/8], Loss: 0.5162\n",
      "Epoch [100/200], Step [8/8], Loss: 0.5601\n",
      "Accuracy of the network on train set: 86.6667 %\n",
      "Accuracy of the network on valid set: 83.3333 %\n",
      "Best validation accuracy so far: 86.6667, at epoch 81\n",
      "\n",
      "New epoch, epoch 101 / 200\n",
      "Epoch [101/200], Step [1/8], Loss: 0.5558\n",
      "Epoch [101/200], Step [2/8], Loss: 0.5776\n",
      "Epoch [101/200], Step [3/8], Loss: 0.6156\n",
      "Epoch [101/200], Step [4/8], Loss: 0.4868\n",
      "Epoch [101/200], Step [5/8], Loss: 0.5353\n",
      "Epoch [101/200], Step [6/8], Loss: 0.6433\n",
      "Epoch [101/200], Step [7/8], Loss: 0.5118\n",
      "Epoch [101/200], Step [8/8], Loss: 0.5003\n",
      "Accuracy of the network on train set: 80.4167 %\n",
      "Accuracy of the network on valid set: 85.0000 %\n",
      "Best validation accuracy so far: 86.6667, at epoch 81\n",
      "\n",
      "New epoch, epoch 102 / 200\n",
      "Epoch [102/200], Step [1/8], Loss: 0.6976\n",
      "Epoch [102/200], Step [2/8], Loss: 0.7964\n",
      "Epoch [102/200], Step [3/8], Loss: 0.3921\n",
      "Epoch [102/200], Step [4/8], Loss: 0.5217\n",
      "Epoch [102/200], Step [5/8], Loss: 1.0715\n",
      "Epoch [102/200], Step [6/8], Loss: 0.6202\n",
      "Epoch [102/200], Step [7/8], Loss: 0.5316\n",
      "Epoch [102/200], Step [8/8], Loss: 0.5731\n",
      "Accuracy of the network on train set: 82.9167 %\n",
      "Accuracy of the network on valid set: 86.6667 %\n",
      "Best validation accuracy so far: 86.6667, at epoch 81\n",
      "\n",
      "New epoch, epoch 103 / 200\n",
      "Epoch [103/200], Step [1/8], Loss: 0.5760\n",
      "Epoch [103/200], Step [2/8], Loss: 0.4825\n",
      "Epoch [103/200], Step [3/8], Loss: 0.4828\n",
      "Epoch [103/200], Step [4/8], Loss: 0.4877\n",
      "Epoch [103/200], Step [5/8], Loss: 0.8329\n",
      "Epoch [103/200], Step [6/8], Loss: 0.8322\n",
      "Epoch [103/200], Step [7/8], Loss: 0.5071\n",
      "Epoch [103/200], Step [8/8], Loss: 0.5153\n",
      "Accuracy of the network on train set: 88.3333 %\n",
      "Accuracy of the network on valid set: 85.0000 %\n",
      "Best validation accuracy so far: 86.6667, at epoch 81\n",
      "\n",
      "New epoch, epoch 104 / 200\n",
      "Epoch [104/200], Step [1/8], Loss: 0.6492\n",
      "Epoch [104/200], Step [2/8], Loss: 0.5921\n",
      "Epoch [104/200], Step [3/8], Loss: 0.4727\n",
      "Epoch [104/200], Step [4/8], Loss: 0.4451\n",
      "Epoch [104/200], Step [5/8], Loss: 0.6201\n",
      "Epoch [104/200], Step [6/8], Loss: 0.5100\n",
      "Epoch [104/200], Step [7/8], Loss: 0.5003\n",
      "Epoch [104/200], Step [8/8], Loss: 0.6921\n",
      "Accuracy of the network on train set: 89.1667 %\n",
      "Accuracy of the network on valid set: 85.0000 %\n",
      "Best validation accuracy so far: 86.6667, at epoch 81\n",
      "\n",
      "New epoch, epoch 105 / 200\n",
      "Epoch [105/200], Step [1/8], Loss: 0.5554\n",
      "Epoch [105/200], Step [2/8], Loss: 0.3689\n",
      "Epoch [105/200], Step [3/8], Loss: 0.4997\n",
      "Epoch [105/200], Step [4/8], Loss: 0.5556\n",
      "Epoch [105/200], Step [5/8], Loss: 0.6764\n",
      "Epoch [105/200], Step [6/8], Loss: 0.5714\n",
      "Epoch [105/200], Step [7/8], Loss: 0.6419\n",
      "Epoch [105/200], Step [8/8], Loss: 0.4802\n",
      "Accuracy of the network on train set: 85.0000 %\n",
      "Accuracy of the network on valid set: 86.6667 %\n",
      "Best validation accuracy so far: 86.6667, at epoch 81\n",
      "\n",
      "New epoch, epoch 106 / 200\n",
      "Epoch [106/200], Step [1/8], Loss: 0.5192\n",
      "Epoch [106/200], Step [2/8], Loss: 0.5128\n",
      "Epoch [106/200], Step [3/8], Loss: 0.7280\n",
      "Epoch [106/200], Step [4/8], Loss: 0.5791\n",
      "Epoch [106/200], Step [5/8], Loss: 0.5764\n",
      "Epoch [106/200], Step [6/8], Loss: 0.6562\n",
      "Epoch [106/200], Step [7/8], Loss: 0.5979\n",
      "Epoch [106/200], Step [8/8], Loss: 0.5882\n",
      "Accuracy of the network on train set: 89.1667 %\n",
      "Accuracy of the network on valid set: 86.6667 %\n",
      "Best validation accuracy so far: 86.6667, at epoch 81\n",
      "\n",
      "New epoch, epoch 107 / 200\n",
      "Epoch [107/200], Step [1/8], Loss: 0.6349\n",
      "Epoch [107/200], Step [2/8], Loss: 0.6310\n",
      "Epoch [107/200], Step [3/8], Loss: 0.5269\n",
      "Epoch [107/200], Step [4/8], Loss: 0.4713\n",
      "Epoch [107/200], Step [5/8], Loss: 0.8062\n",
      "Epoch [107/200], Step [6/8], Loss: 0.4593\n",
      "Epoch [107/200], Step [7/8], Loss: 1.0832\n",
      "Epoch [107/200], Step [8/8], Loss: 0.5347\n",
      "Accuracy of the network on train set: 86.2500 %\n",
      "Accuracy of the network on valid set: 86.6667 %\n",
      "Best validation accuracy so far: 86.6667, at epoch 81\n",
      "\n",
      "New epoch, epoch 108 / 200\n",
      "Epoch [108/200], Step [1/8], Loss: 0.5953\n",
      "Epoch [108/200], Step [2/8], Loss: 0.5471\n",
      "Epoch [108/200], Step [3/8], Loss: 0.7043\n",
      "Epoch [108/200], Step [4/8], Loss: 0.5518\n",
      "Epoch [108/200], Step [5/8], Loss: 0.7967\n",
      "Epoch [108/200], Step [6/8], Loss: 0.5351\n",
      "Epoch [108/200], Step [7/8], Loss: 0.7343\n",
      "Epoch [108/200], Step [8/8], Loss: 0.8499\n",
      "Accuracy of the network on train set: 85.8333 %\n",
      "Accuracy of the network on valid set: 88.3333 %\n",
      "Best validation accuracy so far: 88.3333, at epoch 108\n",
      "\n",
      "New epoch, epoch 109 / 200\n",
      "Epoch [109/200], Step [1/8], Loss: 0.4316\n",
      "Epoch [109/200], Step [2/8], Loss: 0.7724\n",
      "Epoch [109/200], Step [3/8], Loss: 0.5251\n",
      "Epoch [109/200], Step [4/8], Loss: 0.5472\n",
      "Epoch [109/200], Step [5/8], Loss: 0.5605\n",
      "Epoch [109/200], Step [6/8], Loss: 0.7666\n",
      "Epoch [109/200], Step [7/8], Loss: 0.6603\n",
      "Epoch [109/200], Step [8/8], Loss: 0.6353\n",
      "Accuracy of the network on train set: 90.8333 %\n",
      "Accuracy of the network on valid set: 86.6667 %\n",
      "Best validation accuracy so far: 88.3333, at epoch 108\n",
      "\n",
      "New epoch, epoch 110 / 200\n",
      "Epoch [110/200], Step [1/8], Loss: 0.5606\n",
      "Epoch [110/200], Step [2/8], Loss: 0.8231\n",
      "Epoch [110/200], Step [3/8], Loss: 0.4911\n",
      "Epoch [110/200], Step [4/8], Loss: 0.5212\n",
      "Epoch [110/200], Step [5/8], Loss: 0.3979\n",
      "Epoch [110/200], Step [6/8], Loss: 0.4141\n",
      "Epoch [110/200], Step [7/8], Loss: 0.7181\n",
      "Epoch [110/200], Step [8/8], Loss: 0.5035\n",
      "Accuracy of the network on train set: 85.0000 %\n",
      "Accuracy of the network on valid set: 86.6667 %\n",
      "Best validation accuracy so far: 88.3333, at epoch 108\n",
      "\n",
      "New epoch, epoch 111 / 200\n",
      "Epoch [111/200], Step [1/8], Loss: 0.5103\n",
      "Epoch [111/200], Step [2/8], Loss: 0.6527\n",
      "Epoch [111/200], Step [3/8], Loss: 0.6353\n",
      "Epoch [111/200], Step [4/8], Loss: 0.4400\n",
      "Epoch [111/200], Step [5/8], Loss: 0.4400\n",
      "Epoch [111/200], Step [6/8], Loss: 0.5627\n",
      "Epoch [111/200], Step [7/8], Loss: 0.5476\n",
      "Epoch [111/200], Step [8/8], Loss: 0.4856\n",
      "Accuracy of the network on train set: 88.7500 %\n",
      "Accuracy of the network on valid set: 88.3333 %\n",
      "Best validation accuracy so far: 88.3333, at epoch 108\n",
      "\n",
      "New epoch, epoch 112 / 200\n",
      "Epoch [112/200], Step [1/8], Loss: 0.6300\n",
      "Epoch [112/200], Step [2/8], Loss: 0.8348\n",
      "Epoch [112/200], Step [3/8], Loss: 0.5960\n",
      "Epoch [112/200], Step [4/8], Loss: 0.5356\n",
      "Epoch [112/200], Step [5/8], Loss: 0.6909\n",
      "Epoch [112/200], Step [6/8], Loss: 0.5899\n",
      "Epoch [112/200], Step [7/8], Loss: 0.6023\n",
      "Epoch [112/200], Step [8/8], Loss: 0.6575\n",
      "Accuracy of the network on train set: 83.7500 %\n",
      "Accuracy of the network on valid set: 88.3333 %\n",
      "Best validation accuracy so far: 88.3333, at epoch 108\n",
      "\n",
      "New epoch, epoch 113 / 200\n",
      "Epoch [113/200], Step [1/8], Loss: 0.4225\n",
      "Epoch [113/200], Step [2/8], Loss: 0.5680\n",
      "Epoch [113/200], Step [3/8], Loss: 0.4600\n",
      "Epoch [113/200], Step [4/8], Loss: 0.4421\n",
      "Epoch [113/200], Step [5/8], Loss: 0.7629\n",
      "Epoch [113/200], Step [6/8], Loss: 0.7599\n",
      "Epoch [113/200], Step [7/8], Loss: 0.5725\n",
      "Epoch [113/200], Step [8/8], Loss: 0.7261\n",
      "Accuracy of the network on train set: 90.8333 %\n",
      "Accuracy of the network on valid set: 88.3333 %\n",
      "Best validation accuracy so far: 88.3333, at epoch 108\n",
      "\n",
      "New epoch, epoch 114 / 200\n",
      "Epoch [114/200], Step [1/8], Loss: 0.5074\n",
      "Epoch [114/200], Step [2/8], Loss: 0.8472\n",
      "Epoch [114/200], Step [3/8], Loss: 0.4761\n",
      "Epoch [114/200], Step [4/8], Loss: 0.7223\n",
      "Epoch [114/200], Step [5/8], Loss: 0.4948\n",
      "Epoch [114/200], Step [6/8], Loss: 0.4209\n",
      "Epoch [114/200], Step [7/8], Loss: 0.9349\n",
      "Epoch [114/200], Step [8/8], Loss: 0.5234\n",
      "Accuracy of the network on train set: 90.8333 %\n",
      "Accuracy of the network on valid set: 88.3333 %\n",
      "Best validation accuracy so far: 88.3333, at epoch 108\n",
      "\n",
      "New epoch, epoch 115 / 200\n",
      "Epoch [115/200], Step [1/8], Loss: 0.5977\n",
      "Epoch [115/200], Step [2/8], Loss: 0.6249\n",
      "Epoch [115/200], Step [3/8], Loss: 0.4662\n",
      "Epoch [115/200], Step [4/8], Loss: 0.6141\n",
      "Epoch [115/200], Step [5/8], Loss: 0.4601\n",
      "Epoch [115/200], Step [6/8], Loss: 0.6635\n",
      "Epoch [115/200], Step [7/8], Loss: 0.6986\n",
      "Epoch [115/200], Step [8/8], Loss: 0.6411\n",
      "Accuracy of the network on train set: 92.9167 %\n",
      "Accuracy of the network on valid set: 85.0000 %\n",
      "Best validation accuracy so far: 88.3333, at epoch 108\n",
      "\n",
      "New epoch, epoch 116 / 200\n",
      "Epoch [116/200], Step [1/8], Loss: 0.5934\n",
      "Epoch [116/200], Step [2/8], Loss: 0.5388\n",
      "Epoch [116/200], Step [3/8], Loss: 0.5293\n",
      "Epoch [116/200], Step [4/8], Loss: 0.3827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [116/200], Step [5/8], Loss: 0.6060\n",
      "Epoch [116/200], Step [6/8], Loss: 0.6986\n",
      "Epoch [116/200], Step [7/8], Loss: 0.9562\n",
      "Epoch [116/200], Step [8/8], Loss: 0.6314\n",
      "Accuracy of the network on train set: 85.4167 %\n",
      "Accuracy of the network on valid set: 86.6667 %\n",
      "Best validation accuracy so far: 88.3333, at epoch 108\n",
      "\n",
      "New epoch, epoch 117 / 200\n",
      "Epoch [117/200], Step [1/8], Loss: 0.5235\n",
      "Epoch [117/200], Step [2/8], Loss: 0.4288\n",
      "Epoch [117/200], Step [3/8], Loss: 0.6634\n",
      "Epoch [117/200], Step [4/8], Loss: 0.4724\n",
      "Epoch [117/200], Step [5/8], Loss: 0.4412\n",
      "Epoch [117/200], Step [6/8], Loss: 0.5532\n",
      "Epoch [117/200], Step [7/8], Loss: 0.4859\n",
      "Epoch [117/200], Step [8/8], Loss: 0.4540\n",
      "Accuracy of the network on train set: 90.8333 %\n",
      "Accuracy of the network on valid set: 86.6667 %\n",
      "Best validation accuracy so far: 88.3333, at epoch 108\n",
      "\n",
      "New epoch, epoch 118 / 200\n",
      "Epoch [118/200], Step [1/8], Loss: 0.3955\n",
      "Epoch [118/200], Step [2/8], Loss: 0.4537\n",
      "Epoch [118/200], Step [3/8], Loss: 0.4554\n",
      "Epoch [118/200], Step [4/8], Loss: 0.5944\n",
      "Epoch [118/200], Step [5/8], Loss: 0.6578\n",
      "Epoch [118/200], Step [6/8], Loss: 0.5644\n",
      "Epoch [118/200], Step [7/8], Loss: 0.6829\n",
      "Epoch [118/200], Step [8/8], Loss: 0.4289\n",
      "Accuracy of the network on train set: 90.8333 %\n",
      "Accuracy of the network on valid set: 86.6667 %\n",
      "Best validation accuracy so far: 88.3333, at epoch 108\n",
      "\n",
      "New epoch, epoch 119 / 200\n",
      "Epoch [119/200], Step [1/8], Loss: 0.5902\n",
      "Epoch [119/200], Step [2/8], Loss: 0.6642\n",
      "Epoch [119/200], Step [3/8], Loss: 0.6417\n",
      "Epoch [119/200], Step [4/8], Loss: 0.6549\n",
      "Epoch [119/200], Step [5/8], Loss: 0.3958\n",
      "Epoch [119/200], Step [6/8], Loss: 0.8116\n",
      "Epoch [119/200], Step [7/8], Loss: 0.5853\n",
      "Epoch [119/200], Step [8/8], Loss: 0.4879\n",
      "Accuracy of the network on train set: 90.4167 %\n",
      "Accuracy of the network on valid set: 86.6667 %\n",
      "Best validation accuracy so far: 88.3333, at epoch 108\n",
      "\n",
      "New epoch, epoch 120 / 200\n",
      "Epoch [120/200], Step [1/8], Loss: 0.8300\n",
      "Epoch [120/200], Step [2/8], Loss: 0.5860\n",
      "Epoch [120/200], Step [3/8], Loss: 0.7357\n",
      "Epoch [120/200], Step [4/8], Loss: 0.6931\n",
      "Epoch [120/200], Step [5/8], Loss: 0.5922\n",
      "Epoch [120/200], Step [6/8], Loss: 0.5329\n",
      "Epoch [120/200], Step [7/8], Loss: 0.4646\n",
      "Epoch [120/200], Step [8/8], Loss: 0.5190\n",
      "Accuracy of the network on train set: 90.4167 %\n",
      "Accuracy of the network on valid set: 86.6667 %\n",
      "Best validation accuracy so far: 88.3333, at epoch 108\n",
      "\n",
      "New epoch, epoch 121 / 200\n",
      "Epoch [121/200], Step [1/8], Loss: 0.4692\n",
      "Epoch [121/200], Step [2/8], Loss: 0.4180\n",
      "Epoch [121/200], Step [3/8], Loss: 0.7414\n",
      "Epoch [121/200], Step [4/8], Loss: 0.3397\n",
      "Epoch [121/200], Step [5/8], Loss: 0.5213\n",
      "Epoch [121/200], Step [6/8], Loss: 0.5535\n",
      "Epoch [121/200], Step [7/8], Loss: 0.5286\n",
      "Epoch [121/200], Step [8/8], Loss: 0.4565\n",
      "Accuracy of the network on train set: 91.6667 %\n",
      "Accuracy of the network on valid set: 88.3333 %\n",
      "Best validation accuracy so far: 88.3333, at epoch 108\n",
      "\n",
      "New epoch, epoch 122 / 200\n",
      "Epoch [122/200], Step [1/8], Loss: 0.5031\n",
      "Epoch [122/200], Step [2/8], Loss: 0.5739\n",
      "Epoch [122/200], Step [3/8], Loss: 0.3243\n",
      "Epoch [122/200], Step [4/8], Loss: 0.3214\n",
      "Epoch [122/200], Step [5/8], Loss: 0.5921\n",
      "Epoch [122/200], Step [6/8], Loss: 0.8797\n",
      "Epoch [122/200], Step [7/8], Loss: 0.6261\n",
      "Epoch [122/200], Step [8/8], Loss: 0.4145\n",
      "Accuracy of the network on train set: 90.8333 %\n",
      "Accuracy of the network on valid set: 85.0000 %\n",
      "Best validation accuracy so far: 88.3333, at epoch 108\n",
      "\n",
      "New epoch, epoch 123 / 200\n",
      "Epoch [123/200], Step [1/8], Loss: 0.5103\n",
      "Epoch [123/200], Step [2/8], Loss: 0.4556\n",
      "Epoch [123/200], Step [3/8], Loss: 1.0036\n",
      "Epoch [123/200], Step [4/8], Loss: 0.7025\n",
      "Epoch [123/200], Step [5/8], Loss: 0.5999\n",
      "Epoch [123/200], Step [6/8], Loss: 0.6396\n",
      "Epoch [123/200], Step [7/8], Loss: 0.4408\n",
      "Epoch [123/200], Step [8/8], Loss: 0.5595\n",
      "Accuracy of the network on train set: 90.4167 %\n",
      "Accuracy of the network on valid set: 85.0000 %\n",
      "Best validation accuracy so far: 88.3333, at epoch 108\n",
      "\n",
      "New epoch, epoch 124 / 200\n",
      "Epoch [124/200], Step [1/8], Loss: 0.4023\n",
      "Epoch [124/200], Step [2/8], Loss: 0.6845\n",
      "Epoch [124/200], Step [3/8], Loss: 0.7198\n",
      "Epoch [124/200], Step [4/8], Loss: 0.6442\n",
      "Epoch [124/200], Step [5/8], Loss: 0.8879\n",
      "Epoch [124/200], Step [6/8], Loss: 0.5253\n",
      "Epoch [124/200], Step [7/8], Loss: 0.6353\n",
      "Epoch [124/200], Step [8/8], Loss: 0.5464\n",
      "Accuracy of the network on train set: 91.2500 %\n",
      "Accuracy of the network on valid set: 88.3333 %\n",
      "Best validation accuracy so far: 88.3333, at epoch 108\n",
      "\n",
      "New epoch, epoch 125 / 200\n",
      "Epoch [125/200], Step [1/8], Loss: 0.7906\n",
      "Epoch [125/200], Step [2/8], Loss: 0.3991\n",
      "Epoch [125/200], Step [3/8], Loss: 0.5037\n",
      "Epoch [125/200], Step [4/8], Loss: 0.6903\n",
      "Epoch [125/200], Step [5/8], Loss: 0.5970\n",
      "Epoch [125/200], Step [6/8], Loss: 0.5976\n",
      "Epoch [125/200], Step [7/8], Loss: 0.4824\n",
      "Epoch [125/200], Step [8/8], Loss: 0.5392\n",
      "Accuracy of the network on train set: 91.6667 %\n",
      "Accuracy of the network on valid set: 88.3333 %\n",
      "Best validation accuracy so far: 88.3333, at epoch 108\n",
      "\n",
      "New epoch, epoch 126 / 200\n",
      "Epoch [126/200], Step [1/8], Loss: 0.7136\n",
      "Epoch [126/200], Step [2/8], Loss: 0.7361\n",
      "Epoch [126/200], Step [3/8], Loss: 0.7470\n",
      "Epoch [126/200], Step [4/8], Loss: 0.6696\n",
      "Epoch [126/200], Step [5/8], Loss: 0.4592\n",
      "Epoch [126/200], Step [6/8], Loss: 0.3617\n",
      "Epoch [126/200], Step [7/8], Loss: 0.4467\n",
      "Epoch [126/200], Step [8/8], Loss: 0.7057\n",
      "Accuracy of the network on train set: 91.2500 %\n",
      "Accuracy of the network on valid set: 88.3333 %\n",
      "Best validation accuracy so far: 88.3333, at epoch 108\n",
      "\n",
      "New epoch, epoch 127 / 200\n",
      "Epoch [127/200], Step [1/8], Loss: 0.4017\n",
      "Epoch [127/200], Step [2/8], Loss: 0.6980\n",
      "Epoch [127/200], Step [3/8], Loss: 0.5740\n",
      "Epoch [127/200], Step [4/8], Loss: 0.7211\n",
      "Epoch [127/200], Step [5/8], Loss: 0.5899\n",
      "Epoch [127/200], Step [6/8], Loss: 0.6522\n",
      "Epoch [127/200], Step [7/8], Loss: 0.5533\n",
      "Epoch [127/200], Step [8/8], Loss: 0.9855\n",
      "Accuracy of the network on train set: 90.4167 %\n",
      "Accuracy of the network on valid set: 86.6667 %\n",
      "Best validation accuracy so far: 88.3333, at epoch 108\n",
      "\n",
      "New epoch, epoch 128 / 200\n",
      "Epoch [128/200], Step [1/8], Loss: 0.7027\n",
      "Epoch [128/200], Step [2/8], Loss: 0.5561\n",
      "Epoch [128/200], Step [3/8], Loss: 0.4355\n",
      "Epoch [128/200], Step [4/8], Loss: 0.5107\n",
      "Epoch [128/200], Step [5/8], Loss: 0.4381\n",
      "Epoch [128/200], Step [6/8], Loss: 0.5008\n",
      "Epoch [128/200], Step [7/8], Loss: 0.8965\n",
      "Epoch [128/200], Step [8/8], Loss: 0.6634\n",
      "Accuracy of the network on train set: 90.8333 %\n",
      "Accuracy of the network on valid set: 86.6667 %\n",
      "Best validation accuracy so far: 88.3333, at epoch 108\n",
      "\n",
      "New epoch, epoch 129 / 200\n",
      "Epoch [129/200], Step [1/8], Loss: 0.5663\n",
      "Epoch [129/200], Step [2/8], Loss: 0.3927\n",
      "Epoch [129/200], Step [3/8], Loss: 0.7052\n",
      "Epoch [129/200], Step [4/8], Loss: 0.6242\n",
      "Epoch [129/200], Step [5/8], Loss: 0.5789\n",
      "Epoch [129/200], Step [6/8], Loss: 0.5912\n",
      "Epoch [129/200], Step [7/8], Loss: 0.4835\n",
      "Epoch [129/200], Step [8/8], Loss: 0.5401\n",
      "Accuracy of the network on train set: 87.9167 %\n",
      "Accuracy of the network on valid set: 88.3333 %\n",
      "Best validation accuracy so far: 88.3333, at epoch 108\n",
      "\n",
      "New epoch, epoch 130 / 200\n",
      "Epoch [130/200], Step [1/8], Loss: 0.5326\n",
      "Epoch [130/200], Step [2/8], Loss: 0.4376\n",
      "Epoch [130/200], Step [3/8], Loss: 0.6325\n",
      "Epoch [130/200], Step [4/8], Loss: 0.6930\n",
      "Epoch [130/200], Step [5/8], Loss: 0.6816\n",
      "Epoch [130/200], Step [6/8], Loss: 0.6440\n",
      "Epoch [130/200], Step [7/8], Loss: 0.4320\n",
      "Epoch [130/200], Step [8/8], Loss: 0.6262\n",
      "Accuracy of the network on train set: 92.0833 %\n",
      "Accuracy of the network on valid set: 90.0000 %\n",
      "Best validation accuracy so far: 90.0000, at epoch 130\n",
      "\n",
      "New epoch, epoch 131 / 200\n",
      "Epoch [131/200], Step [1/8], Loss: 0.5661\n",
      "Epoch [131/200], Step [2/8], Loss: 0.5865\n",
      "Epoch [131/200], Step [3/8], Loss: 0.6576\n",
      "Epoch [131/200], Step [4/8], Loss: 0.7027\n",
      "Epoch [131/200], Step [5/8], Loss: 0.7002\n",
      "Epoch [131/200], Step [6/8], Loss: 0.6601\n",
      "Epoch [131/200], Step [7/8], Loss: 0.6777\n",
      "Epoch [131/200], Step [8/8], Loss: 0.8149\n",
      "Accuracy of the network on train set: 90.0000 %\n",
      "Accuracy of the network on valid set: 86.6667 %\n",
      "Best validation accuracy so far: 90.0000, at epoch 130\n",
      "\n",
      "New epoch, epoch 132 / 200\n",
      "Epoch [132/200], Step [1/8], Loss: 0.7863\n",
      "Epoch [132/200], Step [2/8], Loss: 0.4788\n",
      "Epoch [132/200], Step [3/8], Loss: 0.5667\n",
      "Epoch [132/200], Step [4/8], Loss: 0.7763\n",
      "Epoch [132/200], Step [5/8], Loss: 0.8133\n",
      "Epoch [132/200], Step [6/8], Loss: 0.5054\n",
      "Epoch [132/200], Step [7/8], Loss: 0.7581\n",
      "Epoch [132/200], Step [8/8], Loss: 0.7048\n",
      "Accuracy of the network on train set: 87.0833 %\n",
      "Accuracy of the network on valid set: 88.3333 %\n",
      "Best validation accuracy so far: 90.0000, at epoch 130\n",
      "\n",
      "New epoch, epoch 133 / 200\n",
      "Epoch [133/200], Step [1/8], Loss: 0.5771\n",
      "Epoch [133/200], Step [2/8], Loss: 0.5544\n",
      "Epoch [133/200], Step [3/8], Loss: 0.6714\n",
      "Epoch [133/200], Step [4/8], Loss: 0.3616\n",
      "Epoch [133/200], Step [5/8], Loss: 0.7526\n",
      "Epoch [133/200], Step [6/8], Loss: 0.4965\n",
      "Epoch [133/200], Step [7/8], Loss: 0.5477\n",
      "Epoch [133/200], Step [8/8], Loss: 0.3760\n",
      "Accuracy of the network on train set: 91.2500 %\n",
      "Accuracy of the network on valid set: 85.0000 %\n",
      "Best validation accuracy so far: 90.0000, at epoch 130\n",
      "\n",
      "New epoch, epoch 134 / 200\n",
      "Epoch [134/200], Step [1/8], Loss: 0.4904\n",
      "Epoch [134/200], Step [2/8], Loss: 0.6677\n",
      "Epoch [134/200], Step [3/8], Loss: 0.5557\n",
      "Epoch [134/200], Step [4/8], Loss: 0.4576\n",
      "Epoch [134/200], Step [5/8], Loss: 0.5258\n",
      "Epoch [134/200], Step [6/8], Loss: 0.6521\n",
      "Epoch [134/200], Step [7/8], Loss: 0.4838\n",
      "Epoch [134/200], Step [8/8], Loss: 0.7135\n",
      "Accuracy of the network on train set: 85.0000 %\n",
      "Accuracy of the network on valid set: 86.6667 %\n",
      "Best validation accuracy so far: 90.0000, at epoch 130\n",
      "\n",
      "New epoch, epoch 135 / 200\n",
      "Epoch [135/200], Step [1/8], Loss: 0.5613\n",
      "Epoch [135/200], Step [2/8], Loss: 0.5672\n",
      "Epoch [135/200], Step [3/8], Loss: 0.6604\n",
      "Epoch [135/200], Step [4/8], Loss: 0.6920\n",
      "Epoch [135/200], Step [5/8], Loss: 0.5760\n",
      "Epoch [135/200], Step [6/8], Loss: 0.5935\n",
      "Epoch [135/200], Step [7/8], Loss: 0.5195\n",
      "Epoch [135/200], Step [8/8], Loss: 0.5527\n",
      "Accuracy of the network on train set: 89.5833 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on valid set: 85.0000 %\n",
      "Best validation accuracy so far: 90.0000, at epoch 130\n",
      "\n",
      "New epoch, epoch 136 / 200\n",
      "Epoch [136/200], Step [1/8], Loss: 0.7285\n",
      "Epoch [136/200], Step [2/8], Loss: 0.5978\n",
      "Epoch [136/200], Step [3/8], Loss: 0.3910\n",
      "Epoch [136/200], Step [4/8], Loss: 0.6680\n",
      "Epoch [136/200], Step [5/8], Loss: 0.4973\n",
      "Epoch [136/200], Step [6/8], Loss: 0.3010\n",
      "Epoch [136/200], Step [7/8], Loss: 0.6690\n",
      "Epoch [136/200], Step [8/8], Loss: 0.4250\n",
      "Accuracy of the network on train set: 87.9167 %\n",
      "Accuracy of the network on valid set: 86.6667 %\n",
      "Best validation accuracy so far: 90.0000, at epoch 130\n",
      "\n",
      "New epoch, epoch 137 / 200\n",
      "Epoch [137/200], Step [1/8], Loss: 0.6565\n",
      "Epoch [137/200], Step [2/8], Loss: 0.4428\n",
      "Epoch [137/200], Step [3/8], Loss: 0.5835\n",
      "Epoch [137/200], Step [4/8], Loss: 0.5629\n",
      "Epoch [137/200], Step [5/8], Loss: 0.5432\n",
      "Epoch [137/200], Step [6/8], Loss: 0.4108\n",
      "Epoch [137/200], Step [7/8], Loss: 0.5978\n",
      "Epoch [137/200], Step [8/8], Loss: 0.5103\n",
      "Accuracy of the network on train set: 91.2500 %\n",
      "Accuracy of the network on valid set: 88.3333 %\n",
      "Best validation accuracy so far: 90.0000, at epoch 130\n",
      "\n",
      "New epoch, epoch 138 / 200\n",
      "Epoch [138/200], Step [1/8], Loss: 0.6704\n",
      "Epoch [138/200], Step [2/8], Loss: 0.6286\n",
      "Epoch [138/200], Step [3/8], Loss: 0.6630\n",
      "Epoch [138/200], Step [4/8], Loss: 0.4824\n",
      "Epoch [138/200], Step [5/8], Loss: 0.7193\n",
      "Epoch [138/200], Step [6/8], Loss: 0.4504\n",
      "Epoch [138/200], Step [7/8], Loss: 0.8062\n",
      "Epoch [138/200], Step [8/8], Loss: 0.8219\n",
      "Accuracy of the network on train set: 89.1667 %\n",
      "Accuracy of the network on valid set: 85.0000 %\n",
      "Best validation accuracy so far: 90.0000, at epoch 130\n",
      "\n",
      "New epoch, epoch 139 / 200\n",
      "Epoch [139/200], Step [1/8], Loss: 0.6046\n",
      "Epoch [139/200], Step [2/8], Loss: 0.4476\n",
      "Epoch [139/200], Step [3/8], Loss: 0.3945\n",
      "Epoch [139/200], Step [4/8], Loss: 0.4307\n",
      "Epoch [139/200], Step [5/8], Loss: 0.5125\n",
      "Epoch [139/200], Step [6/8], Loss: 0.6055\n",
      "Epoch [139/200], Step [7/8], Loss: 0.6350\n",
      "Epoch [139/200], Step [8/8], Loss: 0.5981\n",
      "Accuracy of the network on train set: 91.2500 %\n",
      "Accuracy of the network on valid set: 86.6667 %\n",
      "Best validation accuracy so far: 90.0000, at epoch 130\n",
      "\n",
      "New epoch, epoch 140 / 200\n",
      "Epoch [140/200], Step [1/8], Loss: 0.5232\n",
      "Epoch [140/200], Step [2/8], Loss: 0.6874\n",
      "Epoch [140/200], Step [3/8], Loss: 0.6684\n",
      "Epoch [140/200], Step [4/8], Loss: 0.8260\n",
      "Epoch [140/200], Step [5/8], Loss: 0.4469\n",
      "Epoch [140/200], Step [6/8], Loss: 0.5021\n",
      "Epoch [140/200], Step [7/8], Loss: 0.4542\n",
      "Epoch [140/200], Step [8/8], Loss: 0.7476\n",
      "Accuracy of the network on train set: 86.6667 %\n",
      "Accuracy of the network on valid set: 86.6667 %\n",
      "Best validation accuracy so far: 90.0000, at epoch 130\n",
      "\n",
      "New epoch, epoch 141 / 200\n",
      "Epoch [141/200], Step [1/8], Loss: 0.4652\n",
      "Epoch [141/200], Step [2/8], Loss: 0.6082\n",
      "Epoch [141/200], Step [3/8], Loss: 0.6799\n",
      "Epoch [141/200], Step [4/8], Loss: 0.5127\n",
      "Epoch [141/200], Step [5/8], Loss: 0.4841\n",
      "Epoch [141/200], Step [6/8], Loss: 0.7610\n",
      "Epoch [141/200], Step [7/8], Loss: 0.4624\n",
      "Epoch [141/200], Step [8/8], Loss: 0.6519\n",
      "Accuracy of the network on train set: 92.9167 %\n",
      "Accuracy of the network on valid set: 85.0000 %\n",
      "Best validation accuracy so far: 90.0000, at epoch 130\n",
      "\n",
      "New epoch, epoch 142 / 200\n",
      "Epoch [142/200], Step [1/8], Loss: 0.8130\n",
      "Epoch [142/200], Step [2/8], Loss: 0.5884\n",
      "Epoch [142/200], Step [3/8], Loss: 0.6369\n",
      "Epoch [142/200], Step [4/8], Loss: 0.7415\n",
      "Epoch [142/200], Step [5/8], Loss: 0.5351\n",
      "Epoch [142/200], Step [6/8], Loss: 0.6701\n",
      "Epoch [142/200], Step [7/8], Loss: 0.6858\n",
      "Epoch [142/200], Step [8/8], Loss: 1.2319\n",
      "Accuracy of the network on train set: 89.1667 %\n",
      "Accuracy of the network on valid set: 86.6667 %\n",
      "Best validation accuracy so far: 90.0000, at epoch 130\n",
      "\n",
      "New epoch, epoch 143 / 200\n",
      "Epoch [143/200], Step [1/8], Loss: 0.5576\n",
      "Epoch [143/200], Step [2/8], Loss: 0.5904\n",
      "Epoch [143/200], Step [3/8], Loss: 0.2839\n",
      "Epoch [143/200], Step [4/8], Loss: 0.5559\n",
      "Epoch [143/200], Step [5/8], Loss: 0.5403\n",
      "Epoch [143/200], Step [6/8], Loss: 0.6564\n",
      "Epoch [143/200], Step [7/8], Loss: 0.5129\n",
      "Epoch [143/200], Step [8/8], Loss: 0.8457\n",
      "Accuracy of the network on train set: 89.5833 %\n",
      "Accuracy of the network on valid set: 86.6667 %\n",
      "Best validation accuracy so far: 90.0000, at epoch 130\n",
      "\n",
      "New epoch, epoch 144 / 200\n",
      "Epoch [144/200], Step [1/8], Loss: 0.5300\n",
      "Epoch [144/200], Step [2/8], Loss: 0.5499\n",
      "Epoch [144/200], Step [3/8], Loss: 0.4874\n",
      "Epoch [144/200], Step [4/8], Loss: 1.1593\n",
      "Epoch [144/200], Step [5/8], Loss: 0.6514\n",
      "Epoch [144/200], Step [6/8], Loss: 0.4266\n",
      "Epoch [144/200], Step [7/8], Loss: 0.4109\n",
      "Epoch [144/200], Step [8/8], Loss: 0.6734\n",
      "Accuracy of the network on train set: 90.4167 %\n",
      "Accuracy of the network on valid set: 86.6667 %\n",
      "Best validation accuracy so far: 90.0000, at epoch 130\n",
      "\n",
      "New epoch, epoch 145 / 200\n",
      "Epoch [145/200], Step [1/8], Loss: 0.6739\n",
      "Epoch [145/200], Step [2/8], Loss: 0.5911\n",
      "Epoch [145/200], Step [3/8], Loss: 0.4745\n",
      "Epoch [145/200], Step [4/8], Loss: 0.4591\n",
      "Epoch [145/200], Step [5/8], Loss: 1.2939\n",
      "Epoch [145/200], Step [6/8], Loss: 0.6089\n",
      "Epoch [145/200], Step [7/8], Loss: 0.5328\n",
      "Epoch [145/200], Step [8/8], Loss: 0.5443\n",
      "Accuracy of the network on train set: 89.5833 %\n",
      "Accuracy of the network on valid set: 85.0000 %\n",
      "Best validation accuracy so far: 90.0000, at epoch 130\n",
      "\n",
      "New epoch, epoch 146 / 200\n",
      "Epoch [146/200], Step [1/8], Loss: 0.6311\n",
      "Epoch [146/200], Step [2/8], Loss: 0.4333\n",
      "Epoch [146/200], Step [3/8], Loss: 0.5200\n",
      "Epoch [146/200], Step [4/8], Loss: 0.4659\n",
      "Epoch [146/200], Step [5/8], Loss: 0.5891\n",
      "Epoch [146/200], Step [6/8], Loss: 0.4464\n",
      "Epoch [146/200], Step [7/8], Loss: 0.6436\n",
      "Epoch [146/200], Step [8/8], Loss: 0.7541\n",
      "Accuracy of the network on train set: 87.0833 %\n",
      "Accuracy of the network on valid set: 86.6667 %\n",
      "Best validation accuracy so far: 90.0000, at epoch 130\n",
      "\n",
      "New epoch, epoch 147 / 200\n",
      "Epoch [147/200], Step [1/8], Loss: 0.6069\n",
      "Epoch [147/200], Step [2/8], Loss: 0.5601\n",
      "Epoch [147/200], Step [3/8], Loss: 0.4866\n",
      "Epoch [147/200], Step [4/8], Loss: 0.6151\n",
      "Epoch [147/200], Step [5/8], Loss: 0.5497\n",
      "Epoch [147/200], Step [6/8], Loss: 0.5642\n",
      "Epoch [147/200], Step [7/8], Loss: 0.3403\n",
      "Epoch [147/200], Step [8/8], Loss: 0.7097\n",
      "Accuracy of the network on train set: 87.9167 %\n",
      "Accuracy of the network on valid set: 86.6667 %\n",
      "Best validation accuracy so far: 90.0000, at epoch 130\n",
      "\n",
      "New epoch, epoch 148 / 200\n",
      "Epoch [148/200], Step [1/8], Loss: 0.4162\n",
      "Epoch [148/200], Step [2/8], Loss: 0.4319\n",
      "Epoch [148/200], Step [3/8], Loss: 0.7509\n",
      "Epoch [148/200], Step [4/8], Loss: 0.4700\n",
      "Epoch [148/200], Step [5/8], Loss: 0.4370\n",
      "Epoch [148/200], Step [6/8], Loss: 0.5278\n",
      "Epoch [148/200], Step [7/8], Loss: 0.3875\n",
      "Epoch [148/200], Step [8/8], Loss: 0.5950\n",
      "Accuracy of the network on train set: 91.2500 %\n",
      "Accuracy of the network on valid set: 88.3333 %\n",
      "Best validation accuracy so far: 90.0000, at epoch 130\n",
      "\n",
      "New epoch, epoch 149 / 200\n",
      "Epoch [149/200], Step [1/8], Loss: 0.5050\n",
      "Epoch [149/200], Step [2/8], Loss: 0.3816\n",
      "Epoch [149/200], Step [3/8], Loss: 0.6308\n",
      "Epoch [149/200], Step [4/8], Loss: 0.5543\n",
      "Epoch [149/200], Step [5/8], Loss: 0.6230\n",
      "Epoch [149/200], Step [6/8], Loss: 0.9041\n",
      "Epoch [149/200], Step [7/8], Loss: 0.5512\n",
      "Epoch [149/200], Step [8/8], Loss: 0.7187\n",
      "Accuracy of the network on train set: 91.6667 %\n",
      "Accuracy of the network on valid set: 88.3333 %\n",
      "Best validation accuracy so far: 90.0000, at epoch 130\n",
      "\n",
      "New epoch, epoch 150 / 200\n",
      "Epoch [150/200], Step [1/8], Loss: 0.3924\n",
      "Epoch [150/200], Step [2/8], Loss: 0.5148\n",
      "Epoch [150/200], Step [3/8], Loss: 0.5079\n",
      "Epoch [150/200], Step [4/8], Loss: 0.6454\n",
      "Epoch [150/200], Step [5/8], Loss: 0.3064\n",
      "Epoch [150/200], Step [6/8], Loss: 0.4272\n",
      "Epoch [150/200], Step [7/8], Loss: 0.5504\n",
      "Epoch [150/200], Step [8/8], Loss: 0.9306\n",
      "Accuracy of the network on train set: 84.1667 %\n",
      "Accuracy of the network on valid set: 91.6667 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 151 / 200\n",
      "Epoch [151/200], Step [1/8], Loss: 0.4697\n",
      "Epoch [151/200], Step [2/8], Loss: 0.6121\n",
      "Epoch [151/200], Step [3/8], Loss: 0.4351\n",
      "Epoch [151/200], Step [4/8], Loss: 0.4457\n",
      "Epoch [151/200], Step [5/8], Loss: 0.4088\n",
      "Epoch [151/200], Step [6/8], Loss: 0.5252\n",
      "Epoch [151/200], Step [7/8], Loss: 0.6295\n",
      "Epoch [151/200], Step [8/8], Loss: 0.4771\n",
      "Accuracy of the network on train set: 89.1667 %\n",
      "Accuracy of the network on valid set: 90.0000 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 152 / 200\n",
      "Epoch [152/200], Step [1/8], Loss: 0.4606\n",
      "Epoch [152/200], Step [2/8], Loss: 0.3636\n",
      "Epoch [152/200], Step [3/8], Loss: 0.8197\n",
      "Epoch [152/200], Step [4/8], Loss: 0.6954\n",
      "Epoch [152/200], Step [5/8], Loss: 0.6030\n",
      "Epoch [152/200], Step [6/8], Loss: 0.6215\n",
      "Epoch [152/200], Step [7/8], Loss: 0.4883\n",
      "Epoch [152/200], Step [8/8], Loss: 0.5897\n",
      "Accuracy of the network on train set: 92.0833 %\n",
      "Accuracy of the network on valid set: 88.3333 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 153 / 200\n",
      "Epoch [153/200], Step [1/8], Loss: 0.4620\n",
      "Epoch [153/200], Step [2/8], Loss: 0.5143\n",
      "Epoch [153/200], Step [3/8], Loss: 0.6771\n",
      "Epoch [153/200], Step [4/8], Loss: 0.3946\n",
      "Epoch [153/200], Step [5/8], Loss: 0.8392\n",
      "Epoch [153/200], Step [6/8], Loss: 0.4118\n",
      "Epoch [153/200], Step [7/8], Loss: 0.3873\n",
      "Epoch [153/200], Step [8/8], Loss: 0.4158\n",
      "Accuracy of the network on train set: 91.2500 %\n",
      "Accuracy of the network on valid set: 86.6667 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 154 / 200\n",
      "Epoch [154/200], Step [1/8], Loss: 0.5109\n",
      "Epoch [154/200], Step [2/8], Loss: 0.5430\n",
      "Epoch [154/200], Step [3/8], Loss: 0.7047\n",
      "Epoch [154/200], Step [4/8], Loss: 0.4267\n",
      "Epoch [154/200], Step [5/8], Loss: 0.7178\n",
      "Epoch [154/200], Step [6/8], Loss: 0.4350\n",
      "Epoch [154/200], Step [7/8], Loss: 0.4235\n",
      "Epoch [154/200], Step [8/8], Loss: 0.4318\n",
      "Accuracy of the network on train set: 91.2500 %\n",
      "Accuracy of the network on valid set: 86.6667 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 155 / 200\n",
      "Epoch [155/200], Step [1/8], Loss: 0.6131\n",
      "Epoch [155/200], Step [2/8], Loss: 0.5765\n",
      "Epoch [155/200], Step [3/8], Loss: 0.3986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [155/200], Step [4/8], Loss: 0.3376\n",
      "Epoch [155/200], Step [5/8], Loss: 0.6244\n",
      "Epoch [155/200], Step [6/8], Loss: 0.6891\n",
      "Epoch [155/200], Step [7/8], Loss: 0.4609\n",
      "Epoch [155/200], Step [8/8], Loss: 0.4753\n",
      "Accuracy of the network on train set: 92.5000 %\n",
      "Accuracy of the network on valid set: 88.3333 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 156 / 200\n",
      "Epoch [156/200], Step [1/8], Loss: 0.5350\n",
      "Epoch [156/200], Step [2/8], Loss: 0.5995\n",
      "Epoch [156/200], Step [3/8], Loss: 0.4363\n",
      "Epoch [156/200], Step [4/8], Loss: 0.5901\n",
      "Epoch [156/200], Step [5/8], Loss: 0.5070\n",
      "Epoch [156/200], Step [6/8], Loss: 0.5613\n",
      "Epoch [156/200], Step [7/8], Loss: 0.4182\n",
      "Epoch [156/200], Step [8/8], Loss: 0.5639\n",
      "Accuracy of the network on train set: 90.8333 %\n",
      "Accuracy of the network on valid set: 86.6667 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 157 / 200\n",
      "Epoch [157/200], Step [1/8], Loss: 0.6032\n",
      "Epoch [157/200], Step [2/8], Loss: 0.5078\n",
      "Epoch [157/200], Step [3/8], Loss: 0.5620\n",
      "Epoch [157/200], Step [4/8], Loss: 0.5369\n",
      "Epoch [157/200], Step [5/8], Loss: 0.5915\n",
      "Epoch [157/200], Step [6/8], Loss: 0.7091\n",
      "Epoch [157/200], Step [7/8], Loss: 0.6196\n",
      "Epoch [157/200], Step [8/8], Loss: 0.5576\n",
      "Accuracy of the network on train set: 90.8333 %\n",
      "Accuracy of the network on valid set: 86.6667 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 158 / 200\n",
      "Epoch [158/200], Step [1/8], Loss: 0.4559\n",
      "Epoch [158/200], Step [2/8], Loss: 0.6010\n",
      "Epoch [158/200], Step [3/8], Loss: 0.6114\n",
      "Epoch [158/200], Step [4/8], Loss: 0.6166\n",
      "Epoch [158/200], Step [5/8], Loss: 0.5188\n",
      "Epoch [158/200], Step [6/8], Loss: 0.3786\n",
      "Epoch [158/200], Step [7/8], Loss: 0.4858\n",
      "Epoch [158/200], Step [8/8], Loss: 0.5439\n",
      "Accuracy of the network on train set: 90.8333 %\n",
      "Accuracy of the network on valid set: 90.0000 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 159 / 200\n",
      "Epoch [159/200], Step [1/8], Loss: 0.4758\n",
      "Epoch [159/200], Step [2/8], Loss: 0.5502\n",
      "Epoch [159/200], Step [3/8], Loss: 0.5686\n",
      "Epoch [159/200], Step [4/8], Loss: 0.5644\n",
      "Epoch [159/200], Step [5/8], Loss: 0.7201\n",
      "Epoch [159/200], Step [6/8], Loss: 0.7777\n",
      "Epoch [159/200], Step [7/8], Loss: 0.4604\n",
      "Epoch [159/200], Step [8/8], Loss: 0.4648\n",
      "Accuracy of the network on train set: 90.8333 %\n",
      "Accuracy of the network on valid set: 88.3333 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 160 / 200\n",
      "Epoch [160/200], Step [1/8], Loss: 0.3286\n",
      "Epoch [160/200], Step [2/8], Loss: 0.4483\n",
      "Epoch [160/200], Step [3/8], Loss: 0.4958\n",
      "Epoch [160/200], Step [4/8], Loss: 0.5086\n",
      "Epoch [160/200], Step [5/8], Loss: 0.3620\n",
      "Epoch [160/200], Step [6/8], Loss: 0.4075\n",
      "Epoch [160/200], Step [7/8], Loss: 0.7855\n",
      "Epoch [160/200], Step [8/8], Loss: 0.6076\n",
      "Accuracy of the network on train set: 91.2500 %\n",
      "Accuracy of the network on valid set: 88.3333 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 161 / 200\n",
      "Epoch [161/200], Step [1/8], Loss: 0.7201\n",
      "Epoch [161/200], Step [2/8], Loss: 0.3787\n",
      "Epoch [161/200], Step [3/8], Loss: 0.6723\n",
      "Epoch [161/200], Step [4/8], Loss: 0.6023\n",
      "Epoch [161/200], Step [5/8], Loss: 0.5631\n",
      "Epoch [161/200], Step [6/8], Loss: 0.4710\n",
      "Epoch [161/200], Step [7/8], Loss: 0.6002\n",
      "Epoch [161/200], Step [8/8], Loss: 0.5721\n",
      "Accuracy of the network on train set: 91.2500 %\n",
      "Accuracy of the network on valid set: 88.3333 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 162 / 200\n",
      "Epoch [162/200], Step [1/8], Loss: 0.6480\n",
      "Epoch [162/200], Step [2/8], Loss: 0.3098\n",
      "Epoch [162/200], Step [3/8], Loss: 0.6138\n",
      "Epoch [162/200], Step [4/8], Loss: 0.5911\n",
      "Epoch [162/200], Step [5/8], Loss: 0.6012\n",
      "Epoch [162/200], Step [6/8], Loss: 0.5892\n",
      "Epoch [162/200], Step [7/8], Loss: 0.3899\n",
      "Epoch [162/200], Step [8/8], Loss: 0.5044\n",
      "Accuracy of the network on train set: 92.0833 %\n",
      "Accuracy of the network on valid set: 90.0000 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 163 / 200\n",
      "Epoch [163/200], Step [1/8], Loss: 0.6152\n",
      "Epoch [163/200], Step [2/8], Loss: 0.6504\n",
      "Epoch [163/200], Step [3/8], Loss: 0.7861\n",
      "Epoch [163/200], Step [4/8], Loss: 0.7306\n",
      "Epoch [163/200], Step [5/8], Loss: 0.6629\n",
      "Epoch [163/200], Step [6/8], Loss: 0.4953\n",
      "Epoch [163/200], Step [7/8], Loss: 0.5823\n",
      "Epoch [163/200], Step [8/8], Loss: 1.1253\n",
      "Accuracy of the network on train set: 88.7500 %\n",
      "Accuracy of the network on valid set: 85.0000 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 164 / 200\n",
      "Epoch [164/200], Step [1/8], Loss: 0.5359\n",
      "Epoch [164/200], Step [2/8], Loss: 0.5842\n",
      "Epoch [164/200], Step [3/8], Loss: 0.4843\n",
      "Epoch [164/200], Step [4/8], Loss: 0.4968\n",
      "Epoch [164/200], Step [5/8], Loss: 0.3094\n",
      "Epoch [164/200], Step [6/8], Loss: 0.4153\n",
      "Epoch [164/200], Step [7/8], Loss: 0.5817\n",
      "Epoch [164/200], Step [8/8], Loss: 0.8062\n",
      "Accuracy of the network on train set: 88.7500 %\n",
      "Accuracy of the network on valid set: 86.6667 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 165 / 200\n",
      "Epoch [165/200], Step [1/8], Loss: 0.5792\n",
      "Epoch [165/200], Step [2/8], Loss: 0.5595\n",
      "Epoch [165/200], Step [3/8], Loss: 0.6579\n",
      "Epoch [165/200], Step [4/8], Loss: 0.6436\n",
      "Epoch [165/200], Step [5/8], Loss: 0.5781\n",
      "Epoch [165/200], Step [6/8], Loss: 0.5578\n",
      "Epoch [165/200], Step [7/8], Loss: 0.4916\n",
      "Epoch [165/200], Step [8/8], Loss: 0.5702\n",
      "Accuracy of the network on train set: 92.0833 %\n",
      "Accuracy of the network on valid set: 88.3333 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 166 / 200\n",
      "Epoch [166/200], Step [1/8], Loss: 0.4789\n",
      "Epoch [166/200], Step [2/8], Loss: 0.6136\n",
      "Epoch [166/200], Step [3/8], Loss: 0.4746\n",
      "Epoch [166/200], Step [4/8], Loss: 0.4553\n",
      "Epoch [166/200], Step [5/8], Loss: 0.7204\n",
      "Epoch [166/200], Step [6/8], Loss: 0.4548\n",
      "Epoch [166/200], Step [7/8], Loss: 0.5016\n",
      "Epoch [166/200], Step [8/8], Loss: 0.4788\n",
      "Accuracy of the network on train set: 91.6667 %\n",
      "Accuracy of the network on valid set: 88.3333 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 167 / 200\n",
      "Epoch [167/200], Step [1/8], Loss: 0.6799\n",
      "Epoch [167/200], Step [2/8], Loss: 0.7789\n",
      "Epoch [167/200], Step [3/8], Loss: 0.5873\n",
      "Epoch [167/200], Step [4/8], Loss: 0.5792\n",
      "Epoch [167/200], Step [5/8], Loss: 0.4927\n",
      "Epoch [167/200], Step [6/8], Loss: 0.5514\n",
      "Epoch [167/200], Step [7/8], Loss: 0.4390\n",
      "Epoch [167/200], Step [8/8], Loss: 0.4286\n",
      "Accuracy of the network on train set: 90.8333 %\n",
      "Accuracy of the network on valid set: 88.3333 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 168 / 200\n",
      "Epoch [168/200], Step [1/8], Loss: 0.4123\n",
      "Epoch [168/200], Step [2/8], Loss: 0.4573\n",
      "Epoch [168/200], Step [3/8], Loss: 0.3302\n",
      "Epoch [168/200], Step [4/8], Loss: 0.8952\n",
      "Epoch [168/200], Step [5/8], Loss: 0.4706\n",
      "Epoch [168/200], Step [6/8], Loss: 0.5992\n",
      "Epoch [168/200], Step [7/8], Loss: 0.7661\n",
      "Epoch [168/200], Step [8/8], Loss: 0.7683\n",
      "Accuracy of the network on train set: 88.7500 %\n",
      "Accuracy of the network on valid set: 90.0000 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 169 / 200\n",
      "Epoch [169/200], Step [1/8], Loss: 0.5011\n",
      "Epoch [169/200], Step [2/8], Loss: 0.6558\n",
      "Epoch [169/200], Step [3/8], Loss: 0.6231\n",
      "Epoch [169/200], Step [4/8], Loss: 0.6771\n",
      "Epoch [169/200], Step [5/8], Loss: 0.6908\n",
      "Epoch [169/200], Step [6/8], Loss: 0.7455\n",
      "Epoch [169/200], Step [7/8], Loss: 0.4372\n",
      "Epoch [169/200], Step [8/8], Loss: 0.5059\n",
      "Accuracy of the network on train set: 92.0833 %\n",
      "Accuracy of the network on valid set: 90.0000 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 170 / 200\n",
      "Epoch [170/200], Step [1/8], Loss: 0.4672\n",
      "Epoch [170/200], Step [2/8], Loss: 0.4049\n",
      "Epoch [170/200], Step [3/8], Loss: 0.4596\n",
      "Epoch [170/200], Step [4/8], Loss: 0.4987\n",
      "Epoch [170/200], Step [5/8], Loss: 0.7335\n",
      "Epoch [170/200], Step [6/8], Loss: 0.5199\n",
      "Epoch [170/200], Step [7/8], Loss: 0.4468\n",
      "Epoch [170/200], Step [8/8], Loss: 0.5185\n",
      "Accuracy of the network on train set: 92.0833 %\n",
      "Accuracy of the network on valid set: 88.3333 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 171 / 200\n",
      "Epoch [171/200], Step [1/8], Loss: 0.6585\n",
      "Epoch [171/200], Step [2/8], Loss: 0.6071\n",
      "Epoch [171/200], Step [3/8], Loss: 0.4314\n",
      "Epoch [171/200], Step [4/8], Loss: 0.5739\n",
      "Epoch [171/200], Step [5/8], Loss: 0.7012\n",
      "Epoch [171/200], Step [6/8], Loss: 0.5023\n",
      "Epoch [171/200], Step [7/8], Loss: 0.6414\n",
      "Epoch [171/200], Step [8/8], Loss: 0.5871\n",
      "Accuracy of the network on train set: 91.6667 %\n",
      "Accuracy of the network on valid set: 90.0000 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 172 / 200\n",
      "Epoch [172/200], Step [1/8], Loss: 0.3822\n",
      "Epoch [172/200], Step [2/8], Loss: 0.3580\n",
      "Epoch [172/200], Step [3/8], Loss: 0.4204\n",
      "Epoch [172/200], Step [4/8], Loss: 0.6687\n",
      "Epoch [172/200], Step [5/8], Loss: 0.6978\n",
      "Epoch [172/200], Step [6/8], Loss: 0.6291\n",
      "Epoch [172/200], Step [7/8], Loss: 0.5382\n",
      "Epoch [172/200], Step [8/8], Loss: 0.9103\n",
      "Accuracy of the network on train set: 90.0000 %\n",
      "Accuracy of the network on valid set: 86.6667 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 173 / 200\n",
      "Epoch [173/200], Step [1/8], Loss: 0.5121\n",
      "Epoch [173/200], Step [2/8], Loss: 0.5647\n",
      "Epoch [173/200], Step [3/8], Loss: 0.4035\n",
      "Epoch [173/200], Step [4/8], Loss: 0.5201\n",
      "Epoch [173/200], Step [5/8], Loss: 0.5014\n",
      "Epoch [173/200], Step [6/8], Loss: 0.2877\n",
      "Epoch [173/200], Step [7/8], Loss: 0.6627\n",
      "Epoch [173/200], Step [8/8], Loss: 0.4615\n",
      "Accuracy of the network on train set: 92.5000 %\n",
      "Accuracy of the network on valid set: 88.3333 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 174 / 200\n",
      "Epoch [174/200], Step [1/8], Loss: 0.6002\n",
      "Epoch [174/200], Step [2/8], Loss: 0.6523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [174/200], Step [3/8], Loss: 0.5720\n",
      "Epoch [174/200], Step [4/8], Loss: 0.6226\n",
      "Epoch [174/200], Step [5/8], Loss: 0.4156\n",
      "Epoch [174/200], Step [6/8], Loss: 0.8076\n",
      "Epoch [174/200], Step [7/8], Loss: 0.5637\n",
      "Epoch [174/200], Step [8/8], Loss: 0.3952\n",
      "Accuracy of the network on train set: 93.7500 %\n",
      "Accuracy of the network on valid set: 88.3333 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 175 / 200\n",
      "Epoch [175/200], Step [1/8], Loss: 0.4605\n",
      "Epoch [175/200], Step [2/8], Loss: 0.6497\n",
      "Epoch [175/200], Step [3/8], Loss: 0.3913\n",
      "Epoch [175/200], Step [4/8], Loss: 0.4392\n",
      "Epoch [175/200], Step [5/8], Loss: 0.6629\n",
      "Epoch [175/200], Step [6/8], Loss: 1.0930\n",
      "Epoch [175/200], Step [7/8], Loss: 0.6140\n",
      "Epoch [175/200], Step [8/8], Loss: 0.4068\n",
      "Accuracy of the network on train set: 92.0833 %\n",
      "Accuracy of the network on valid set: 91.6667 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 176 / 200\n",
      "Epoch [176/200], Step [1/8], Loss: 0.4421\n",
      "Epoch [176/200], Step [2/8], Loss: 0.5041\n",
      "Epoch [176/200], Step [3/8], Loss: 0.6678\n",
      "Epoch [176/200], Step [4/8], Loss: 0.8504\n",
      "Epoch [176/200], Step [5/8], Loss: 0.5729\n",
      "Epoch [176/200], Step [6/8], Loss: 0.4339\n",
      "Epoch [176/200], Step [7/8], Loss: 0.4242\n",
      "Epoch [176/200], Step [8/8], Loss: 0.4462\n",
      "Accuracy of the network on train set: 92.5000 %\n",
      "Accuracy of the network on valid set: 90.0000 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 177 / 200\n",
      "Epoch [177/200], Step [1/8], Loss: 0.4731\n",
      "Epoch [177/200], Step [2/8], Loss: 0.4721\n",
      "Epoch [177/200], Step [3/8], Loss: 0.7366\n",
      "Epoch [177/200], Step [4/8], Loss: 0.4347\n",
      "Epoch [177/200], Step [5/8], Loss: 0.5554\n",
      "Epoch [177/200], Step [6/8], Loss: 0.6535\n",
      "Epoch [177/200], Step [7/8], Loss: 0.4905\n",
      "Epoch [177/200], Step [8/8], Loss: 0.4504\n",
      "Accuracy of the network on train set: 92.0833 %\n",
      "Accuracy of the network on valid set: 90.0000 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 178 / 200\n",
      "Epoch [178/200], Step [1/8], Loss: 0.6246\n",
      "Epoch [178/200], Step [2/8], Loss: 0.5820\n",
      "Epoch [178/200], Step [3/8], Loss: 0.4056\n",
      "Epoch [178/200], Step [4/8], Loss: 0.3768\n",
      "Epoch [178/200], Step [5/8], Loss: 0.4873\n",
      "Epoch [178/200], Step [6/8], Loss: 0.4670\n",
      "Epoch [178/200], Step [7/8], Loss: 0.5427\n",
      "Epoch [178/200], Step [8/8], Loss: 0.4686\n",
      "Accuracy of the network on train set: 92.0833 %\n",
      "Accuracy of the network on valid set: 90.0000 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 179 / 200\n",
      "Epoch [179/200], Step [1/8], Loss: 0.7958\n",
      "Epoch [179/200], Step [2/8], Loss: 0.6294\n",
      "Epoch [179/200], Step [3/8], Loss: 0.5512\n",
      "Epoch [179/200], Step [4/8], Loss: 0.4875\n",
      "Epoch [179/200], Step [5/8], Loss: 0.5978\n",
      "Epoch [179/200], Step [6/8], Loss: 0.3764\n",
      "Epoch [179/200], Step [7/8], Loss: 0.4777\n",
      "Epoch [179/200], Step [8/8], Loss: 0.5467\n",
      "Accuracy of the network on train set: 90.8333 %\n",
      "Accuracy of the network on valid set: 86.6667 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 180 / 200\n",
      "Epoch [180/200], Step [1/8], Loss: 0.4573\n",
      "Epoch [180/200], Step [2/8], Loss: 0.6079\n",
      "Epoch [180/200], Step [3/8], Loss: 0.5402\n",
      "Epoch [180/200], Step [4/8], Loss: 0.6478\n",
      "Epoch [180/200], Step [5/8], Loss: 0.5805\n",
      "Epoch [180/200], Step [6/8], Loss: 0.5677\n",
      "Epoch [180/200], Step [7/8], Loss: 0.4609\n",
      "Epoch [180/200], Step [8/8], Loss: 0.4547\n",
      "Accuracy of the network on train set: 91.6667 %\n",
      "Accuracy of the network on valid set: 90.0000 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 181 / 200\n",
      "Epoch [181/200], Step [1/8], Loss: 0.5415\n",
      "Epoch [181/200], Step [2/8], Loss: 0.7032\n",
      "Epoch [181/200], Step [3/8], Loss: 0.6275\n",
      "Epoch [181/200], Step [4/8], Loss: 0.6988\n",
      "Epoch [181/200], Step [5/8], Loss: 0.3887\n",
      "Epoch [181/200], Step [6/8], Loss: 0.4365\n",
      "Epoch [181/200], Step [7/8], Loss: 0.3986\n",
      "Epoch [181/200], Step [8/8], Loss: 0.5669\n",
      "Accuracy of the network on train set: 91.2500 %\n",
      "Accuracy of the network on valid set: 88.3333 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 182 / 200\n",
      "Epoch [182/200], Step [1/8], Loss: 0.6049\n",
      "Epoch [182/200], Step [2/8], Loss: 0.4181\n",
      "Epoch [182/200], Step [3/8], Loss: 0.3381\n",
      "Epoch [182/200], Step [4/8], Loss: 0.2987\n",
      "Epoch [182/200], Step [5/8], Loss: 0.5507\n",
      "Epoch [182/200], Step [6/8], Loss: 0.5722\n",
      "Epoch [182/200], Step [7/8], Loss: 0.5257\n",
      "Epoch [182/200], Step [8/8], Loss: 0.5528\n",
      "Accuracy of the network on train set: 92.0833 %\n",
      "Accuracy of the network on valid set: 88.3333 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 183 / 200\n",
      "Epoch [183/200], Step [1/8], Loss: 0.6110\n",
      "Epoch [183/200], Step [2/8], Loss: 0.5273\n",
      "Epoch [183/200], Step [3/8], Loss: 0.5125\n",
      "Epoch [183/200], Step [4/8], Loss: 0.5517\n",
      "Epoch [183/200], Step [5/8], Loss: 0.4486\n",
      "Epoch [183/200], Step [6/8], Loss: 0.4617\n",
      "Epoch [183/200], Step [7/8], Loss: 0.7793\n",
      "Epoch [183/200], Step [8/8], Loss: 0.4132\n",
      "Accuracy of the network on train set: 93.3333 %\n",
      "Accuracy of the network on valid set: 90.0000 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 184 / 200\n",
      "Epoch [184/200], Step [1/8], Loss: 0.4233\n",
      "Epoch [184/200], Step [2/8], Loss: 0.4305\n",
      "Epoch [184/200], Step [3/8], Loss: 0.5012\n",
      "Epoch [184/200], Step [4/8], Loss: 0.8181\n",
      "Epoch [184/200], Step [5/8], Loss: 0.4098\n",
      "Epoch [184/200], Step [6/8], Loss: 0.7226\n",
      "Epoch [184/200], Step [7/8], Loss: 0.4502\n",
      "Epoch [184/200], Step [8/8], Loss: 0.5061\n",
      "Accuracy of the network on train set: 90.8333 %\n",
      "Accuracy of the network on valid set: 88.3333 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 185 / 200\n",
      "Epoch [185/200], Step [1/8], Loss: 0.5915\n",
      "Epoch [185/200], Step [2/8], Loss: 0.3945\n",
      "Epoch [185/200], Step [3/8], Loss: 0.2761\n",
      "Epoch [185/200], Step [4/8], Loss: 0.3552\n",
      "Epoch [185/200], Step [5/8], Loss: 0.4548\n",
      "Epoch [185/200], Step [6/8], Loss: 0.5383\n",
      "Epoch [185/200], Step [7/8], Loss: 0.4579\n",
      "Epoch [185/200], Step [8/8], Loss: 0.4752\n",
      "Accuracy of the network on train set: 92.0833 %\n",
      "Accuracy of the network on valid set: 90.0000 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 186 / 200\n",
      "Epoch [186/200], Step [1/8], Loss: 0.3806\n",
      "Epoch [186/200], Step [2/8], Loss: 0.5864\n",
      "Epoch [186/200], Step [3/8], Loss: 0.3547\n",
      "Epoch [186/200], Step [4/8], Loss: 0.7862\n",
      "Epoch [186/200], Step [5/8], Loss: 0.4756\n",
      "Epoch [186/200], Step [6/8], Loss: 0.3528\n",
      "Epoch [186/200], Step [7/8], Loss: 0.7431\n",
      "Epoch [186/200], Step [8/8], Loss: 0.3862\n",
      "Accuracy of the network on train set: 92.0833 %\n",
      "Accuracy of the network on valid set: 90.0000 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 187 / 200\n",
      "Epoch [187/200], Step [1/8], Loss: 0.7767\n",
      "Epoch [187/200], Step [2/8], Loss: 0.5159\n",
      "Epoch [187/200], Step [3/8], Loss: 0.6521\n",
      "Epoch [187/200], Step [4/8], Loss: 0.5906\n",
      "Epoch [187/200], Step [5/8], Loss: 0.3798\n",
      "Epoch [187/200], Step [6/8], Loss: 0.4920\n",
      "Epoch [187/200], Step [7/8], Loss: 0.4773\n",
      "Epoch [187/200], Step [8/8], Loss: 0.5043\n",
      "Accuracy of the network on train set: 92.9167 %\n",
      "Accuracy of the network on valid set: 88.3333 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 188 / 200\n",
      "Epoch [188/200], Step [1/8], Loss: 0.6005\n",
      "Epoch [188/200], Step [2/8], Loss: 0.4818\n",
      "Epoch [188/200], Step [3/8], Loss: 0.3777\n",
      "Epoch [188/200], Step [4/8], Loss: 0.4748\n",
      "Epoch [188/200], Step [5/8], Loss: 0.4863\n",
      "Epoch [188/200], Step [6/8], Loss: 0.5956\n",
      "Epoch [188/200], Step [7/8], Loss: 0.7927\n",
      "Epoch [188/200], Step [8/8], Loss: 0.5509\n",
      "Accuracy of the network on train set: 93.3333 %\n",
      "Accuracy of the network on valid set: 86.6667 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 189 / 200\n",
      "Epoch [189/200], Step [1/8], Loss: 0.6273\n",
      "Epoch [189/200], Step [2/8], Loss: 0.8079\n",
      "Epoch [189/200], Step [3/8], Loss: 0.4755\n",
      "Epoch [189/200], Step [4/8], Loss: 0.4805\n",
      "Epoch [189/200], Step [5/8], Loss: 0.2880\n",
      "Epoch [189/200], Step [6/8], Loss: 0.4806\n",
      "Epoch [189/200], Step [7/8], Loss: 0.4906\n",
      "Epoch [189/200], Step [8/8], Loss: 0.7405\n",
      "Accuracy of the network on train set: 91.6667 %\n",
      "Accuracy of the network on valid set: 88.3333 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 190 / 200\n",
      "Epoch [190/200], Step [1/8], Loss: 0.3780\n",
      "Epoch [190/200], Step [2/8], Loss: 0.4309\n",
      "Epoch [190/200], Step [3/8], Loss: 0.8079\n",
      "Epoch [190/200], Step [4/8], Loss: 0.4183\n",
      "Epoch [190/200], Step [5/8], Loss: 0.9949\n",
      "Epoch [190/200], Step [6/8], Loss: 0.9447\n",
      "Epoch [190/200], Step [7/8], Loss: 0.6836\n",
      "Epoch [190/200], Step [8/8], Loss: 0.6668\n",
      "Accuracy of the network on train set: 92.5000 %\n",
      "Accuracy of the network on valid set: 88.3333 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 191 / 200\n",
      "Epoch [191/200], Step [1/8], Loss: 0.3691\n",
      "Epoch [191/200], Step [2/8], Loss: 0.4911\n",
      "Epoch [191/200], Step [3/8], Loss: 0.7387\n",
      "Epoch [191/200], Step [4/8], Loss: 0.4301\n",
      "Epoch [191/200], Step [5/8], Loss: 0.4328\n",
      "Epoch [191/200], Step [6/8], Loss: 0.5375\n",
      "Epoch [191/200], Step [7/8], Loss: 0.6757\n",
      "Epoch [191/200], Step [8/8], Loss: 0.4246\n",
      "Accuracy of the network on train set: 91.2500 %\n",
      "Accuracy of the network on valid set: 85.0000 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 192 / 200\n",
      "Epoch [192/200], Step [1/8], Loss: 0.4437\n",
      "Epoch [192/200], Step [2/8], Loss: 0.5437\n",
      "Epoch [192/200], Step [3/8], Loss: 0.4888\n",
      "Epoch [192/200], Step [4/8], Loss: 0.7030\n",
      "Epoch [192/200], Step [5/8], Loss: 0.4336\n",
      "Epoch [192/200], Step [6/8], Loss: 0.4946\n",
      "Epoch [192/200], Step [7/8], Loss: 0.5958\n",
      "Epoch [192/200], Step [8/8], Loss: 0.7146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on train set: 92.0833 %\n",
      "Accuracy of the network on valid set: 90.0000 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 193 / 200\n",
      "Epoch [193/200], Step [1/8], Loss: 0.5887\n",
      "Epoch [193/200], Step [2/8], Loss: 0.5084\n",
      "Epoch [193/200], Step [3/8], Loss: 0.3956\n",
      "Epoch [193/200], Step [4/8], Loss: 0.3245\n",
      "Epoch [193/200], Step [5/8], Loss: 0.6673\n",
      "Epoch [193/200], Step [6/8], Loss: 0.7504\n",
      "Epoch [193/200], Step [7/8], Loss: 0.5415\n",
      "Epoch [193/200], Step [8/8], Loss: 0.4017\n",
      "Accuracy of the network on train set: 92.0833 %\n",
      "Accuracy of the network on valid set: 90.0000 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 194 / 200\n",
      "Epoch [194/200], Step [1/8], Loss: 0.5535\n",
      "Epoch [194/200], Step [2/8], Loss: 0.4986\n",
      "Epoch [194/200], Step [3/8], Loss: 0.5630\n",
      "Epoch [194/200], Step [4/8], Loss: 0.3311\n",
      "Epoch [194/200], Step [5/8], Loss: 0.5648\n",
      "Epoch [194/200], Step [6/8], Loss: 0.3881\n",
      "Epoch [194/200], Step [7/8], Loss: 0.4981\n",
      "Epoch [194/200], Step [8/8], Loss: 0.6505\n",
      "Accuracy of the network on train set: 91.6667 %\n",
      "Accuracy of the network on valid set: 90.0000 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 195 / 200\n",
      "Epoch [195/200], Step [1/8], Loss: 0.6644\n",
      "Epoch [195/200], Step [2/8], Loss: 0.4316\n",
      "Epoch [195/200], Step [3/8], Loss: 0.6058\n",
      "Epoch [195/200], Step [4/8], Loss: 0.5627\n",
      "Epoch [195/200], Step [5/8], Loss: 0.6273\n",
      "Epoch [195/200], Step [6/8], Loss: 0.3615\n",
      "Epoch [195/200], Step [7/8], Loss: 0.5486\n",
      "Epoch [195/200], Step [8/8], Loss: 0.4819\n",
      "Accuracy of the network on train set: 91.2500 %\n",
      "Accuracy of the network on valid set: 86.6667 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 196 / 200\n",
      "Epoch [196/200], Step [1/8], Loss: 0.2846\n",
      "Epoch [196/200], Step [2/8], Loss: 0.5027\n",
      "Epoch [196/200], Step [3/8], Loss: 0.5353\n",
      "Epoch [196/200], Step [4/8], Loss: 0.4962\n",
      "Epoch [196/200], Step [5/8], Loss: 0.7113\n",
      "Epoch [196/200], Step [6/8], Loss: 0.7228\n",
      "Epoch [196/200], Step [7/8], Loss: 0.5979\n",
      "Epoch [196/200], Step [8/8], Loss: 0.4549\n",
      "Accuracy of the network on train set: 92.9167 %\n",
      "Accuracy of the network on valid set: 88.3333 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 197 / 200\n",
      "Epoch [197/200], Step [1/8], Loss: 0.3059\n",
      "Epoch [197/200], Step [2/8], Loss: 0.3721\n",
      "Epoch [197/200], Step [3/8], Loss: 0.4742\n",
      "Epoch [197/200], Step [4/8], Loss: 0.6004\n",
      "Epoch [197/200], Step [5/8], Loss: 0.8749\n",
      "Epoch [197/200], Step [6/8], Loss: 0.5013\n",
      "Epoch [197/200], Step [7/8], Loss: 0.5169\n",
      "Epoch [197/200], Step [8/8], Loss: 0.6895\n",
      "Accuracy of the network on train set: 92.0833 %\n",
      "Accuracy of the network on valid set: 90.0000 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 198 / 200\n",
      "Epoch [198/200], Step [1/8], Loss: 0.3624\n",
      "Epoch [198/200], Step [2/8], Loss: 0.5163\n",
      "Epoch [198/200], Step [3/8], Loss: 0.6555\n",
      "Epoch [198/200], Step [4/8], Loss: 0.5621\n",
      "Epoch [198/200], Step [5/8], Loss: 0.8613\n",
      "Epoch [198/200], Step [6/8], Loss: 0.5425\n",
      "Epoch [198/200], Step [7/8], Loss: 0.3157\n",
      "Epoch [198/200], Step [8/8], Loss: 0.5774\n",
      "Accuracy of the network on train set: 92.5000 %\n",
      "Accuracy of the network on valid set: 90.0000 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 199 / 200\n",
      "Epoch [199/200], Step [1/8], Loss: 0.6547\n",
      "Epoch [199/200], Step [2/8], Loss: 0.5586\n",
      "Epoch [199/200], Step [3/8], Loss: 0.5461\n",
      "Epoch [199/200], Step [4/8], Loss: 0.5086\n",
      "Epoch [199/200], Step [5/8], Loss: 0.8352\n",
      "Epoch [199/200], Step [6/8], Loss: 0.4512\n",
      "Epoch [199/200], Step [7/8], Loss: 0.3977\n",
      "Epoch [199/200], Step [8/8], Loss: 0.3564\n",
      "Accuracy of the network on train set: 92.9167 %\n",
      "Accuracy of the network on valid set: 90.0000 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n",
      "\n",
      "New epoch, epoch 200 / 200\n",
      "Epoch [200/200], Step [1/8], Loss: 0.5468\n",
      "Epoch [200/200], Step [2/8], Loss: 0.9669\n",
      "Epoch [200/200], Step [3/8], Loss: 0.8257\n",
      "Epoch [200/200], Step [4/8], Loss: 0.2931\n",
      "Epoch [200/200], Step [5/8], Loss: 0.5709\n",
      "Epoch [200/200], Step [6/8], Loss: 0.4674\n",
      "Epoch [200/200], Step [7/8], Loss: 0.5358\n",
      "Epoch [200/200], Step [8/8], Loss: 0.4123\n",
      "Accuracy of the network on train set: 92.0833 %\n",
      "Accuracy of the network on valid set: 88.3333 %\n",
      "Best validation accuracy so far: 91.6667, at epoch 150\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "num_epochs = 200\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "total_step = len(train_loader)\n",
    "eval_accuracy(\"train\", train_loader, model)\n",
    "eval_accuracy(\"valid\", valid_loader, model)\n",
    "valid_accs = []\n",
    "loss_list = []\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    loss_count = 0\n",
    "    print('\\nNew epoch, epoch {} / {}'.format(epoch+1, num_epochs))\n",
    "    for i, (x, t) in enumerate(train_loader):\n",
    "        # Move tensors to the configured device\n",
    "        x = x.to(device)\n",
    "        t = t.to(device)\n",
    "      \n",
    "        # Forward pass\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, t)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        #torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5) # Gradient clipping\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        # # Weight Clipping\n",
    "        #for p in model.parameters():\n",
    "        #    p.data.clamp_(-0.01, 0.01)\n",
    "        \n",
    "        total_loss += loss\n",
    "        loss_count += 1\n",
    "        \n",
    "        if (i+1) % 1 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                 .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "    \n",
    "    eval_accuracy(\"train\", train_loader, model)\n",
    "    valid_acc = eval_accuracy(\"valid\", valid_loader, model)\n",
    "    valid_accs.append(valid_acc)\n",
    "    avgloss = total_loss / loss_count\n",
    "    loss_list.append(avgloss)\n",
    "    \n",
    "    print(\"Best validation accuracy so far: {:.4f}, at epoch {}\".format(np.max(np.array(valid_accs)), np.argmax(np.array(valid_accs))+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd49588d",
   "metadata": {},
   "source": [
    "## 1.5 Plot loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1a77d043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Loss ----------------------------\n",
    "fig, axes = plt.subplots(1,1)\n",
    "axes.plot(np.arange(len(loss_list)), loss_list, label='train')\n",
    "axes.set_title('Loss Plots', fontsize=20)\n",
    "axes.set_xlabel('Iteration (x10)')\n",
    "axes.set_ylabel('Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecde659",
   "metadata": {},
   "source": [
    "Batch Norm casues the gradient to explode. For this example, there is no large gradient spike. Gradient clip maybe not have good effects of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe8b9af",
   "metadata": {},
   "source": [
    "## 1.6 Generate a test set and plot the test result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "567ceb98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Decision Boundary \n",
    "x, t = load_data(0) # Test dataset\n",
    "\n",
    "h = 0.001\n",
    "x_min, x_max = x[:, 0].min() - .1, x[:, 0].max() + .1\n",
    "y_min, y_max = x[:, 1].min() - .1, x[:, 1].max() + .1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "X = np.c_[xx.ravel(), yy.ravel()]\n",
    "X = torch.Tensor(X)\n",
    "\n",
    "with torch.no_grad():\n",
    "  model.eval() # turn off dropout and batch_norm\n",
    "  score = model.forward(X)\n",
    "predict_cls = np.argmax(score.data.numpy(), axis=1)\n",
    "Z = predict_cls.reshape(xx.shape)\n",
    "fig, axes = plt.subplots(1,1)\n",
    "axes.set_title('Decision Boundary', fontsize=20)\n",
    "axes.contourf(xx, yy, Z)\n",
    "axes.axis('off')\n",
    "\n",
    "# Plot Data \n",
    "N = 100\n",
    "CLS_NUM = 3\n",
    "markers = ['o', 'x', '^']\n",
    "for i in range(CLS_NUM):\n",
    "    axes.scatter(x[i*N:(i+1)*N, 0], x[i*N:(i+1)*N, 1], s=40, marker=markers[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de306b9",
   "metadata": {},
   "source": [
    "# Thanks for reading!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c2d70c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
