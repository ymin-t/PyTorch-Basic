{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d551888",
   "metadata": {},
   "source": [
    "# Introduction to PyTorch\n",
    "\n",
    "Before reading this introduction you should know a bit of:\n",
    "1. Python - look at [official tutorial](https://docs.python.org/3/tutorial/)\n",
    "2. Linear Algebra and Matrices - look at [Coursera tutorial](https://www.coursera.org/learn/linear-algebra-machine-learning) and/or book [Introduction to Applied Linear Algebra](http://vmls-book.stanford.edu/vmls.pdf)\n",
    "\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "\n",
    "From official NumPy page we could read that\n",
    "\n",
    "\n",
    "PyTorch is a Python-based scientific computing package targeted at two sets of audiences:\n",
    "\n",
    "A replacement for NumPy to use the power of GPUs\n",
    "a deep learning research platform that provides maximum flexibility and speed\n",
    "\n",
    "<hr>\n",
    "\n",
    "\n",
    "Contrary to NumPy, PyTorch was designed mostly to work on **GPU**. PyTorch represents n-dimensional array object as  `Tensor`. To install PyTorch library, go to [link](https://pytorch.org/get-started/locally/). There are also very good tutorials:\n",
    "* [Official PyTorch tutorials](https://pytorch.org/tutorials/)\n",
    "* [Deep Learning for Natural Language Processing with Pytorch](https://github.com/rguthrie3/DeepLearningForNLPInPytorch/blob/master/Deep%20Learning%20for%20Natural%20Language%20Processing%20with%20Pytorch.ipynb) \n",
    "\n",
    "Here we want give you a quick crash course of using PyTorch library, especially Tensor object. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7566e476",
   "metadata": {},
   "source": [
    "## 1. Basics: creating a PyTorch tensor\n",
    "\n",
    "Important notes:\n",
    "* all items in PyTorch array (a.k.a. `Tensor`) cantain only one data type e.g. `int8`, `float32`, ... ([all datatypes](https://pytorch.org/docs/stable/tensors.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "278dabb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ff760f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1d Tensor from Python list (with 'int32' type)\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7], dtype=torch.int32)\n",
      "torch.Size([8])\n",
      "\n",
      "2d Tensor from Python list of lists  (with `float32` type)\n",
      "tensor([[ 0.,  1.],\n",
      "        [ 2.,  3.],\n",
      "        [ 4.,  5.],\n",
      "        [ 6.,  7.],\n",
      "        [ 8.,  9.],\n",
      "        [10., 11.],\n",
      "        [12., 13.],\n",
      "        [14., 15.]])\n",
      "torch.Size([8, 2])\n"
     ]
    }
   ],
   "source": [
    "# creating tensor from python list\n",
    "\n",
    "print(\"1d Tensor from Python list (with 'int32' type)\")\n",
    "list1d = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "tensor1d = torch.tensor(list1d, dtype=torch.int32)\n",
    "print(tensor1d)\n",
    "print(tensor1d.size())\n",
    "print()\n",
    "\n",
    "\n",
    "print(\"2d Tensor from Python list of lists  (with `float32` type)\")\n",
    "list2d = [[0, 1], [2, 3], [4, 5], [6, 7], [8, 9], [10, 11], [12, 13], [14, 15]]\n",
    "tensor2d = torch.tensor(list2d, dtype=torch.float32)\n",
    "print(tensor2d)\n",
    "print(tensor2d.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa82063f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2d random tensor (with `float32` type)\n",
      "tensor([[0.6430, 0.3873],\n",
      "        [0.1354, 0.0599],\n",
      "        [0.7824, 0.7412],\n",
      "        [0.8572, 0.6942],\n",
      "        [0.3523, 0.6777],\n",
      "        [0.3822, 0.2264],\n",
      "        [0.4619, 0.0919],\n",
      "        [0.4787, 0.5517]])\n",
      "torch.Size([8, 2])\n",
      "\n",
      "2d tensor with uniform distribution\n",
      "tensor([[ 6.0738],\n",
      "        [-9.7094],\n",
      "        [ 5.7095],\n",
      "        [ 2.4143],\n",
      "        [-3.3079],\n",
      "        [-2.7146],\n",
      "        [ 6.3315],\n",
      "        [ 3.7597]])\n",
      "torch.Size([8, 1])\n"
     ]
    }
   ],
   "source": [
    "# creating tensor using distribution\n",
    "\n",
    "print(\"2d random tensor (with `float32` type)\")\n",
    "tensor2d_random = torch.rand(8, 2, dtype=torch.float32)\n",
    "print(tensor2d_random)\n",
    "print(tensor2d_random.size())\n",
    "print()\n",
    "\n",
    "\n",
    "print(\"2d tensor with uniform distribution\")\n",
    "tensor2d_uniform = torch.FloatTensor(8, 1).uniform_(-10, 10)\n",
    "print(tensor2d_uniform)\n",
    "print(tensor2d_uniform.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8652d9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1d tensor based on linearly spaced vector\n",
      "tensor([0., 1., 2., 3., 4., 5., 6., 7.])\n",
      "torch.Size([8])\n",
      "\n",
      "1d tensor based on `arange` mechanism\n",
      "tensor([0, 3, 6, 9])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "# creating tensor using linspace and arange\n",
    "\n",
    "print(\"1d tensor based on linearly spaced vector\")\n",
    "tensor1d_linspace = torch.linspace(0, 7, steps=8, dtype=torch.float32)\n",
    "print(tensor1d_linspace)\n",
    "print(tensor1d_linspace.size())\n",
    "print()\n",
    "\n",
    "\n",
    "print(\"1d tensor based on `arange` mechanism\")\n",
    "tensor1d_arange = torch.arange(0, 10, 3)\n",
    "print(tensor1d_arange)\n",
    "print(tensor1d_arange.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ba3550e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2d zeros tensor\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "torch.Size([2, 4])\n",
      "\n",
      "2d ones tensor\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "#Creating 0 and 1 tensor\n",
    "\n",
    "print(\"2d zeros tensor\")\n",
    "torch2d_zeros = torch.zeros([2, 4])\n",
    "print(torch2d_zeros)\n",
    "print(torch2d_zeros.size())\n",
    "print()\n",
    "\n",
    "print(\"2d ones tensor\")\n",
    "torch2d_ones = torch.ones([2, 4])\n",
    "print(torch2d_ones)\n",
    "print(torch2d_ones.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254a42aa",
   "metadata": {},
   "source": [
    "## 1.2 Basics: extracting specific values from tensors\n",
    "\n",
    "Important notes:\n",
    "* tensor can be indexed using the standard Python x[obj] syntax, wherea x is the array and obj the selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4441f9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7], dtype=torch.int32)\n",
      "tensor([[ 0.,  1.],\n",
      "        [ 2.,  3.],\n",
      "        [ 4.,  5.],\n",
      "        [ 6.,  7.],\n",
      "        [ 8.,  9.],\n",
      "        [10., 11.],\n",
      "        [12., 13.],\n",
      "        [14., 15.]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor1d)\n",
    "print(tensor2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "84a06964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get specific element\n",
      "tensor(3.)\n"
     ]
    }
   ],
   "source": [
    "# single element\n",
    "\n",
    "print(\"Get specific element\")\n",
    "print(tensor2d[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b409682f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The basic slice syntax is i:j:k\n",
      "tensor([0, 2, 4], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# slicing using i:j:k where i is starting element, j is the stopping element, k is the step\n",
    "\n",
    "print(\"The basic slice syntax is i:j:k\")\n",
    "print(tensor1d[0:6:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3cfe9561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract only one dimension from multidimensional ndarray\n",
      "tensor([ 0.,  2.,  4.,  6.,  8., 10., 12., 14.])\n",
      "torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "# slicing first row from a 2x2\n",
    "\n",
    "print(\"Extract only one dimension from multidimensional ndarray\") \n",
    "print(tensor2d[:, 0])\n",
    "print(tensor2d[:, 0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d7fdcc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boolean array indexing\n",
      "tensor([0, 2, 4, 6], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# slicing using bolean\n",
    "\n",
    "print(\"Boolean array indexing\") \n",
    "print(tensor1d[([True, False, True, False, True, False, True, False])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f819fb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using condition statement for indexing array\n",
      "tensor([0, 2, 4, 6], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# slicing with a condition\n",
    "\n",
    "print(\"Using condition statement for indexing array\") \n",
    "print(tensor1d[(tensor1d % 2 == 0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6175a99",
   "metadata": {},
   "source": [
    "## 1.2 Nan and infinite representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7bbb9856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "represent `not a number value`\n",
      "tensor(nan)\n"
     ]
    }
   ],
   "source": [
    "# represent nan in tensor\n",
    "\n",
    "print(\"represent `not a number value`\")\n",
    "print(torch.tensor(float('nan')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6ea4c50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "represent `infinite`\n",
      "tensor(inf)\n"
     ]
    }
   ],
   "source": [
    "# represent inf in tensor\n",
    "\n",
    "print(\"represent `infinite`\")\n",
    "print(torch.tensor(float('Inf')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393cfdf8",
   "metadata": {},
   "source": [
    "## 1.3 Basics: sum, min, max, mean, reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cf793195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.],\n",
      "        [ 2.,  3.],\n",
      "        [ 4.,  5.],\n",
      "        [ 6.,  7.],\n",
      "        [ 8.,  9.],\n",
      "        [10., 11.],\n",
      "        [12., 13.],\n",
      "        [14., 15.]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7f7d261c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate mean, max and min in tensor\n",
      "sum  tensor(120.)\n",
      "max  tensor(15.)\n",
      "min  tensor(0.)\n",
      "mean  tensor(7.5000)\n"
     ]
    }
   ],
   "source": [
    "print(\"calculate mean, max and min in tensor\")\n",
    "print(\"sum \", tensor2d.sum())\n",
    "print(\"max \", tensor2d.max())\n",
    "print(\"min \", tensor2d.min())\n",
    "print(\"mean \", tensor2d.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e8bdcdce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate max on different axis\n",
      "column max:  torch.return_types.max(\n",
      "values=tensor([14., 15.]),\n",
      "indices=tensor([7, 7]))\n",
      "\n",
      "row max:  tensor([ 1.,  3.,  5.,  7.,  9., 11., 13., 15.])\n"
     ]
    }
   ],
   "source": [
    "print(\"calculate max on different axis\")\n",
    "print(\"column max: \", tensor2d.max(dim=0))\n",
    "print()\n",
    "print(\"row max: \", tensor2d.max(dim=1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ca54fb",
   "metadata": {},
   "source": [
    "## 1.4 Reshaping and resizing\n",
    "\n",
    "Resizing or reshaping a tensor is an incredibly important tensor operation that is used all the time. The interesting thing is that there seems to be many ways of achieving the same behavior.\n",
    "\n",
    "view, reshape, resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7286631e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.],\n",
       "        [ 2.,  3.],\n",
       "        [ 4.,  5.],\n",
       "        [ 6.,  7.],\n",
       "        [ 8.,  9.],\n",
       "        [10., 11.],\n",
       "        [12., 13.],\n",
       "        [14., 15.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "570a0228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshape 2d tensor using view\n",
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.],\n",
      "        [12., 13., 14., 15.]])\n",
      "torch.Size([4, 4])\n",
      "\n",
      "reshape 2d tensor using view 2\n",
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.],\n",
      "        [12., 13., 14., 15.]])\n",
      "torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "# view\n",
    "\n",
    "print(\"reshape 2d tensor using view\")\n",
    "newtensor2d = tensor2d.view(4, 4)\n",
    "print(newtensor2d)\n",
    "print(newtensor2d.size())\n",
    "print()\n",
    "\n",
    "print(\"reshape 2d tensor using view 2\")\n",
    "newtensor2d = tensor2d.view(4, -1)  # the second dimention is adjusted to size of the matrix\n",
    "print(newtensor2d)\n",
    "print(newtensor2d.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "19ebc1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshape 2d tensor using reshape\n",
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.],\n",
      "        [12., 13., 14., 15.]])\n",
      "torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "# reshape\n",
    "\n",
    "print(\"reshape 2d tensor using reshape\")\n",
    "newtensor2d = tensor2d.reshape(4, 4)\n",
    "print(newtensor2d)\n",
    "print(newtensor2d.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dcff4fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshape 2d tensor using resize\n",
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.],\n",
      "        [12., 13., 14., 15.]])\n",
      "torch.Size([4, 4])\n",
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.],\n",
      "        [12., 13., 14., 15.]])\n"
     ]
    }
   ],
   "source": [
    "# resize\n",
    "# this method permantly affect the size of the input tensor\n",
    "\n",
    "print(\"reshape 2d tensor using resize\")\n",
    "newtensor2d = tensor2d.resize_(4, 4)\n",
    "print(newtensor2d)\n",
    "print(newtensor2d.size())\n",
    "\n",
    "print(tensor2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df3b4f5",
   "metadata": {},
   "source": [
    "## 1.5 Basic math operation (plus, minus,times,divide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "37dfeabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize tensor, x1\n",
      "tensor([[4., 1., 1.],\n",
      "        [5., 1., 1.],\n",
      "        [6., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Initialize tensor, x1\")\n",
    "x1 = torch.ones([3, 3], dtype=torch.float32)\n",
    "x1[:, 0] = torch.tensor([4., 5., 6.])\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1f47aa5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transpose x1 tensor\n",
      "tensor([[4., 5., 6.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Transpose x1 tensor\")\n",
    "print(x1.transpose(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0c1ce2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiply by scalar, x2=x1*3\n",
      "tensor([[12.,  3.,  3.],\n",
      "        [15.,  3.,  3.],\n",
      "        [18.,  3.,  3.]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Multiply by scalar, x2=x1*3\")\n",
    "x2 = x1*3.\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ee0b127b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element-wise sum, x1+x2\n",
      "tensor([[16.,  4.,  4.],\n",
      "        [20.,  4.,  4.],\n",
      "        [24.,  4.,  4.]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Element-wise sum, x1+x2\")\n",
    "print(x1+x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b676b2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element-wise subtract, x1-x2\n",
      "tensor([[ -8.,  -2.,  -2.],\n",
      "        [-10.,  -2.,  -2.],\n",
      "        [-12.,  -2.,  -2.]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Element-wise subtract, x1-x2\")\n",
    "print(x1-x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cb186a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element-wise product, x1*x2\n",
      "tensor([[ 48.,   3.,   3.],\n",
      "        [ 75.,   3.,   3.],\n",
      "        [108.,   3.,   3.]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Element-wise product, x1*x2\")\n",
    "print(x1*x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9e25aecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element-wise divide, x1/x2\n",
      "tensor([[0.3333, 0.3333, 0.3333],\n",
      "        [0.3333, 0.3333, 0.3333],\n",
      "        [0.3333, 0.3333, 0.3333]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Element-wise divide, x1/x2\")\n",
    "print(x1/x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a2ce589a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element-wise power, x2^2\n",
      "tensor([[144.,   9.,   9.],\n",
      "        [225.,   9.,   9.],\n",
      "        [324.,   9.,   9.]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Element-wise power, x2^2\")\n",
    "print(torch.pow(x2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0ac7877f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element-wise square root, sqrt(x2)\n",
      "tensor([[3.4641, 1.7321, 1.7321],\n",
      "        [3.8730, 1.7321, 1.7321],\n",
      "        [4.2426, 1.7321, 1.7321]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Element-wise square root, sqrt(x2)\")\n",
    "print(torch.sqrt(x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3de4c478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix multiplication, x1*x2\n",
      "tensor([[ 81.,  18.,  18.],\n",
      "        [ 93.,  21.,  21.],\n",
      "        [105.,  24.,  24.]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Matrix multiplication, x1*x2\")\n",
    "print(x1.mm(x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "eaf83e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector multiplication, x1*x2[0]\n",
      "tensor([54., 66., 78.])\n"
     ]
    }
   ],
   "source": [
    "print(\"Vector multiplication, x1*x2[0]\")\n",
    "print(x1.mm(x2[0].view([-1, 1])).view(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c0225c",
   "metadata": {},
   "source": [
    "## 1.6 Broadcasting\n",
    "\n",
    "In short, if a PyTorch operation supports broadcast, then its Tensor arguments can be automatically expanded to be of equal sizes (see more at [this link](https://pytorch.org/docs/stable/notes/broadcasting.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d7c95ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add vector x2 to each row of matrix x1 using broadcasting mechanism\n",
      "tensor([[ 1,  4],\n",
      "        [ 3,  6],\n",
      "        [ 5,  8],\n",
      "        [ 7, 10],\n",
      "        [ 9, 12],\n",
      "        [11, 14],\n",
      "        [13, 16],\n",
      "        [15, 18]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Add vector x2 to each row of matrix x1 using broadcasting mechanism\")\n",
    "x1 = torch.tensor([[0, 1], [2, 3], [4, 5], [6, 7], [8, 9], [10, 11], [12, 13], [14, 15]])\n",
    "x2 = torch.tensor([1, 3])\n",
    "print(x1+x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ef67c1",
   "metadata": {},
   "source": [
    "## 1.7 Dimension\n",
    "\n",
    "One of the main takeaways from that experience is that an intuition on dimensionality and tensor operations in general is a huge plus. This gets especially important for things like batching.\n",
    "\n",
    "(n,) v. (1, n) does have different dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "712ad058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1012, -0.9094,  0.2257])\n",
      "torch.Size([3])\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(3)\n",
    "print(a)\n",
    "print(a.shape)\n",
    "print(a.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "722b303b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9801,  0.8352, -0.6674]])\n",
      "torch.Size([1, 3])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "b = torch.randn(1,3)\n",
    "print(b)\n",
    "print(b.shape)\n",
    "print(b.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81256ea",
   "metadata": {},
   "source": [
    "## 1.8 Adding or reducing dimension\n",
    "\n",
    "As mentioned earlier, batch dimension is something that becomes very important later on. Some PyTorch layers, most notably RNNs, even have an argument batch_first, which accepts a boolean value. \n",
    "\n",
    "A common operation that is used when dealing with inputs is .squeeze(), or its inverse, .unsqueeze()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "38ce68f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1012, -0.9094,  0.2257])\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "df6d17b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1012, -0.9094,  0.2257]])\n",
      "\n",
      "tensor([[ 0.1012],\n",
      "        [-0.9094],\n",
      "        [ 0.2257]])\n"
     ]
    }
   ],
   "source": [
    "# adding a dimension in the 0 shape\n",
    "new_a_0 = a.unsqueeze(0)\n",
    "print(new_a_0)\n",
    "print()\n",
    "\n",
    "# adding a dimension in the 1 shape\n",
    "new_a_1 = a.unsqueeze(1)\n",
    "print(new_a_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "77230e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1012, -0.9094,  0.2257])\n",
      "tensor([ 0.1012, -0.9094,  0.2257])\n"
     ]
    }
   ],
   "source": [
    "# remove dimension in 0 shape\n",
    "print(new_a_0.squeeze(0))\n",
    "\n",
    "# remove dimension in 1 shape\n",
    "print(new_a_1.squeeze(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d66271",
   "metadata": {},
   "source": [
    "## 1.9 Concat\n",
    "\n",
    "Concatenation and stacking are very commonly used in deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ac8f9c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 9, 4, 7],\n",
      "         [8, 8, 8, 6],\n",
      "         [5, 0, 9, 8]],\n",
      "\n",
      "        [[8, 1, 4, 1],\n",
      "         [3, 9, 3, 8],\n",
      "         [5, 8, 4, 4]]], dtype=torch.int32)\n",
      "\n",
      "tensor([[[4, 6, 1, 5],\n",
      "         [1, 0, 1, 8],\n",
      "         [1, 6, 8, 3]],\n",
      "\n",
      "        [[2, 7, 5, 8],\n",
      "         [3, 3, 8, 8],\n",
      "         [2, 4, 4, 5]]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "m1 = (torch.rand(2, 3, 4) * 10).int()\n",
    "m2 = (torch.rand(2, 3, 4) * 10).int()\n",
    "print(m1)\n",
    "print()\n",
    "print(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "15c99bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 9, 4, 7],\n",
      "         [8, 8, 8, 6],\n",
      "         [5, 0, 9, 8]],\n",
      "\n",
      "        [[8, 1, 4, 1],\n",
      "         [3, 9, 3, 8],\n",
      "         [5, 8, 4, 4]],\n",
      "\n",
      "        [[4, 6, 1, 5],\n",
      "         [1, 0, 1, 8],\n",
      "         [1, 6, 8, 3]],\n",
      "\n",
      "        [[2, 7, 5, 8],\n",
      "         [3, 3, 8, 8],\n",
      "         [2, 4, 4, 5]]], dtype=torch.int32)\n",
      "torch.Size([4, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# perform the first concatenation along the 0-th dimension\n",
    "\n",
    "cat0 = torch.cat((m1, m2), 0)\n",
    "print(cat0)\n",
    "print(cat0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3d2c53f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 9, 4, 7],\n",
      "         [8, 8, 8, 6],\n",
      "         [5, 0, 9, 8],\n",
      "         [4, 6, 1, 5],\n",
      "         [1, 0, 1, 8],\n",
      "         [1, 6, 8, 3]],\n",
      "\n",
      "        [[8, 1, 4, 1],\n",
      "         [3, 9, 3, 8],\n",
      "         [5, 8, 4, 4],\n",
      "         [2, 7, 5, 8],\n",
      "         [3, 3, 8, 8],\n",
      "         [2, 4, 4, 5]]], dtype=torch.int32)\n",
      "torch.Size([2, 6, 4])\n"
     ]
    }
   ],
   "source": [
    "# perform the first concatenation along the 1-th dimension\n",
    "\n",
    "cat1 = torch.cat((m1, m2), 1)\n",
    "print(cat1)\n",
    "print(cat1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "cd20c5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 9, 4, 7, 4, 6, 1, 5],\n",
      "         [8, 8, 8, 6, 1, 0, 1, 8],\n",
      "         [5, 0, 9, 8, 1, 6, 8, 3]],\n",
      "\n",
      "        [[8, 1, 4, 1, 2, 7, 5, 8],\n",
      "         [3, 9, 3, 8, 3, 3, 8, 8],\n",
      "         [5, 8, 4, 4, 2, 4, 4, 5]]], dtype=torch.int32)\n",
      "torch.Size([2, 3, 8])\n"
     ]
    }
   ],
   "source": [
    "# perform the first concatenation along the 2-th dimension\n",
    "\n",
    "cat2 = torch.cat((m1, m2), 2)\n",
    "print(cat2)\n",
    "print(cat2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784fc433",
   "metadata": {},
   "source": [
    "### Thank for reading & good bye!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
